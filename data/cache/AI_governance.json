{
  "title": "Regulation of artificial intelligence",
  "summary": "Regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI). It is part of the broader regulation of algorithms. The regulatory and policy landscape for AI is an emerging issue in jurisdictions worldwide, including for international organizations without direct enforcement power like the IEEE or the OECD.",
  "content": "Regulation of artificial intelligence Guidelines and laws to regulate AI .mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" · \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"} .mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0} .mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}} Part of a series on Legal aspects of computing Information privacy law File sharing Computer trespass Data mining Hyperlinking and framing Regulation of algorithms Regulation of AI Software law Software licenses Spamming .mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}} v t e Regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI). It is part of the broader regulation of algorithms . [ 1 ] [ 2 ] The regulatory and policy landscape for AI is an emerging issue in jurisdictions worldwide, including for international organizations without direct enforcement power like the IEEE or the OECD . [ 3 ] Since 2016, numerous AI ethics guidelines have been published in order to maintain social control over the technology. [ 4 ] Regulation is deemed necessary to both foster AI innovation and manage associated risks. Furthermore, organizations deploying AI have a central role to play in creating and implementing trustworthy AI , adhering to established principles, and taking accountability for mitigating risks. [ 5 ] Regulating AI through mechanisms such as review boards can also be seen as social means to approach the AI control problem . [ 6 ] [ 7 ] Background According to Stanford University 's 2025 AI Index, legislative mentions of AI rose 21.3% across 75 countries since 2023, marking a ninefold increase since 2016. The U.S. federal agencies introduced 59 AI-related regulations in 2024—more than double the number in 2023. [ 8 ] [ 9 ] In 2024, nearly 700 AI-related bills were introduced across 45 states, up from 191 in 2023. [ 10 ] There is currently no broad consensus on the degree or mechanics of AI regulation. Several prominent figures in the field, including Elon Musk , Sam Altman , Dario Amodei , and Demis Hassabis have publicly called for immediate regulation of AI. [ 11 ] [ 12 ] [ 13 ] [ 14 ] In 2023, following ChatGPT-4 's creation, Elon Musk and others signed an open letter urging a moratorium on the training of more powerful AI systems. [ 15 ] Others, such as Mark Zuckerberg and Marc Andreessen , have warned about the risk of preemptive regulation stifling innovation. [ 16 ] [ 17 ] In a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\". [ 8 ] Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity. [ 18 ] In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\". [ 19 ] [ 20 ] In 2023 the United Kingdom started a series of international summits on AI with the AI Safety Summit . It was followed by the AI Seoul Summit in 2024, and the AI Action Summit in Paris in 2025. [ 21 ] Perspectives The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI. [ 22 ] Public administration and policy considerations generally focus on the technical and economic implications and on trustworthy and human-centered AI systems, [ 23 ] regulation of artificial superintelligence , [ 24 ] the risks and biases of machine-learning algorithms, the explainability of model outputs, [ 25 ] and the tension between open source AI and unchecked AI use. [ 26 ] [ 27 ] [ 28 ] There have been both hard law and soft law proposals to regulate AI. [ 29 ] Some legal scholars have noted that hard law approaches to AI regulation have substantial challenges. [ 30 ] [ 31 ] Among the challenges, AI technology is rapidly evolving leading to a \"pacing problem\" where traditional laws and regulations often cannot keep up with emerging applications and their associated risks and benefits. [ 30 ] [ 31 ] Similarly, the diversity of AI applications challenges existing regulatory agencies, which often have limited jurisdictional scope. [ 30 ] As an alternative, some legal scholars argue that soft law approaches to AI regulation are promising, as they offer greater flexibility to adapt to emerging technologies and the evolving nature of AI applications. [ 30 ] [ 31 ] However, soft law approaches often lack substantial enforcement potential. [ 30 ] [ 32 ] Cason Schmit, Megan Doerr, and Jennifer Wagner proposed the creation of a quasi-governmental regulator by leveraging intellectual property rights (i.e., copyleft licensing) in certain AI objects (i.e., AI models and training datasets) and delegating enforcement rights to a designated enforcement entity. [ 33 ] They argue that AI can be licensed under terms that require adherence to specified ethical practices and codes of conduct. (e.g., soft law principles). [ 33 ] Prominent youth organizations focused on AI, namely Encode Justice, have also issued comprehensive agendas calling for more stringent AI regulations and public-private partnerships . [ 34 ] [ 35 ] AI regulation could derive from basic principles. A 2020 Berkman Klein Center for Internet &amp; Society meta-review of existing sets of principles, such as the Asilomar Principles and the Beijing Principles, identified eight such basic principles: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and respect for human values. [ 36 ] AI law and regulations have been divided into three main topics, namely governance of autonomous intelligence systems, responsibility and accountability for the systems, and privacy and safety issues. [ 37 ] A public administration approach sees a relationship between AI law and regulation, the ethics of AI , and 'AI society', defined as workforce substitution and transformation, social acceptance and trust in AI, and the transformation of human to machine interaction. [ 38 ] The development of public sector strategies for management and regulation of AI is deemed necessary at the local, national, [ 39 ] and international levels [ 40 ] and in a variety of fields, from public service management [ 41 ] and accountability [ 42 ] to law enforcement, [ 40 ] [ 43 ] healthcare (especially the concept of a Human Guarantee), [ 44 ] [ 45 ] [ 46 ] [ 47 ] [ 48 ] the financial sector, [ 39 ] [ 49 ] robotics, [ 50 ] [ 51 ] autonomous vehicles, [ 50 ] the military [ 52 ] and national security, [ 53 ] and international law. [ 54 ] [ 55 ] Henry Kissinger , Eric Schmidt , and Daniel Huttenlocher published a joint statement in November 2021 entitled \"Being Human in an Age of AI\", calling for a government commission to regulate AI. [ 56 ] In 2025, the UK and US governments declined to sign an international agreement on AI at the AI Action Summit in Paris. The agreement was described as proposing an open, inclusive and ethical approach to AI development, including environmental protection measures. US Vice President JD Vance argued that the agreement would be detrimental to the growth of the AI industry. The UK government added that the agreement \"didn't provide enough practical clarity on global governance, nor sufficiently address harder questions around national security\". [ 57 ] As a response to the AI control problem .mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}} Main article: AI control problem Regulation of AI can be seen as positive social means to manage the AI control problem (the need to ensure long-term beneficial AI), with other social responses such as doing nothing or banning being seen as impractical, and approaches such as enhancing human capabilities through transhumanism techniques like brain-computer interfaces being seen as potentially complementary. [ 7 ] [ 58 ] Regulation of research into artificial general intelligence (AGI) focuses on the role of review boards, from university or corporation to international levels, and on encouraging research into AI safety , [ 58 ] together with the possibility of differential intellectual progress (prioritizing protective strategies over risky strategies in AI development) or conducting international mass surveillance to perform AGI arms control. [ 7 ] For instance, the 'AGI Nanny' is a proposed strategy, potentially under the control of humanity, for preventing the creation of a dangerous superintelligence as well as for addressing other major threats to human well-being, such as subversion of the global financial system, until a true superintelligence can be safely created. It entails the creation of a smarter-than-human, but not superintelligent, AGI system connected to a large surveillance network, with the goal of monitoring humanity and protecting it from danger. [ 7 ] Regulation of conscious, ethically aware AGIs focuses on how to integrate them with existing human society and can be divided into considerations of their legal standing and of their moral rights. [ 7 ] Regulation of AI has been seen as restrictive, with a risk of preventing the development of AGI. [ 50 ] Global guidance Organizations polled largely agree that companies developing foundation models will be responsible for associated risks (rather than those using it), and that global governance is required to address risks from generative AI . [ 59 ] The development of a global governance board to regulate AI development was suggested at least as early as 2017. [ 60 ] In December 2018, Canada and France announced plans for a G7-backed International Panel on Artificial Intelligence, modeled on the International Panel on Climate Change , to study the global effects of AI on people and economies and to steer AI development. [ 61 ] In 2019, the Panel was renamed the Global Partnership on AI. [ 62 ] [ 63 ] The Global Partnership on Artificial Intelligence (GPAI) was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology, as outlined in the OECD Principles on Artificial Intelligence (2019). [ 64 ] The 15 founding members of the Global Partnership on Artificial Intelligence are Australia, Canada, the European Union, France, Germany, India, Italy, Japan, the Republic of Korea, Mexico, New Zealand, Singapore, Slovenia, the United States and the UK. In 2023, the GPAI has 29 members. [ 65 ] The GPAI Secretariat is hosted by the OECD in Paris, France. GPAI's mandate covers four themes, two of which are supported by the International Centre of Expertise in Montréal for the Advancement of Artificial Intelligence, namely, responsible AI and data governance. A corresponding centre of excellence in Paris will support the other two themes on the future of work, and on innovation and commercialization. GPAI also investigated how AI can be leveraged to respond to the COVID-19 pandemic. [ 64 ] The OECD AI Principles [ 66 ] were adopted in May 2019, and the G20 AI Principles in June 2019. [ 63 ] [ 67 ] [ 68 ] In September 2019 the World Economic Forum issued ten 'AI Government Procurement Guidelines'. [ 69 ] In February 2020, the European Union published its draft strategy paper for promoting and regulating AI. [ 40 ] At the United Nations (UN), several entities have begun to promote and discuss aspects of AI regulation and policy, including the UNICRI Centre for AI and Robotics . [ 53 ] In partnership with INTERPOL, UNICRI's Centre issued the report AI and Robotics for Law Enforcement in April 2019 [ 70 ] and the follow-up report Towards Responsible AI Innovation in May 2020. [ 43 ] At UNESCO 's Scientific 40th session in November 2019, the organization commenced a two-year process to achieve a \"global standard-setting instrument on ethics of artificial intelligence\". In pursuit of this goal, UNESCO forums and conferences on AI were held to gather stakeholder views. A draft text of a Recommendation on the Ethics of AI of the UNESCO Ad Hoc Expert Group was issued in September 2020 and included a call for legislative gaps to be filled. [ 71 ] UNESCO tabled the international instrument on the ethics of AI for adoption at its General Conference in November 2021; [ 64 ] this was subsequently adopted. [ 72 ] While the UN is making progress with the global management of AI, its institutional and legal capability to manage the AGI existential risk is more limited. [ 73 ] Recent research has indicated that countries will also begin to use artificial intelligence as a tool for national cyberdefense. AI is a new factor in the cyber arms industry, as it can be used for defense purposes. Therefore, academics urge that nations should establish regulations for the use of AI, similar to how there are regulations for other military industries. [ 74 ] In recent years, academic researchers have made more efforts to promote multilateral dialogue and policy development, advocating for the adoption of international frameworks that govern the deployment of AI in military and cybersecurity contexts, with a strong emphasis on human rights and international humanitarian law. [ 75 ] Initiatives such as the Munich Convention on AI, Data and Human Rights, which brought together scholars from various academic institutions, have called for a binding international agreement to protect human rights in the age of AI. [ 76 ] A key element of such initiatives is identifying common ground between different regional approaches, such as those of the African Union and the Council of Europe. [ 77 ] Regional and national regulation Timeline of strategies, action plans and policy papers setting defining national, regional and international approaches to AI [ 78 ] The regulatory and policy landscape for AI is an emerging issue in regional and national jurisdictions globally, for example in the European Union [ 79 ] and Russia. [ 80 ] Since early 2016, many national, regional and international authorities have begun adopting strategies, actions plans and policy papers on AI. [ 81 ] [ 82 ] These documents cover a wide range of topics such as regulation and governance, as well as industrial strategy, research, talent and infrastructure. [ 23 ] [ 83 ] Different countries have approached the problem in different ways. Regarding the three largest economies, it has been said that \"the United States is following a market-driven approach, China is advancing a state-driven approach, and the EU is pursuing a rights-driven approach.\" [ 84 ] African Union The African Union has increasingly been active in the field. Most importantly, the African Commission on Human and Peoples' Rights published a study on AI and human rights and advocated for an African Framework Convention on AI and Human Rights. [ 85 ] This initiative builds on earlier debates within the AU, particularly discussions on autonomous lethal weapons, which African representatives had previously raised in international forums. [ 75 ] A distinctive feature of the proposed African Framework is its strong emphasis on collective rights, as enshrined in the African Charter on Human and Peoples' Rights . This approach is situated within the broader debate on aligning AI governance with African values, including ethical traditions such as Ubuntu (\"humanity to others\"). [ 86 ] [ 87 ] [ 88 ] Australia In October 2023, the Australian Computer Society , Business Council of Australia , Australian Chamber of Commerce and Industry , Ai Group (aka Australian Industry Group) , Council of Small Business Organisations Australia, and Tech Council of Australia jointly published an open letter calling for a national approach to AI strategy. [ 89 ] The letter backs the federal government establishing a whole-of-government AI taskforce. [ 89 ] Additionally, in August 2024, the Australian government set a Voluntary AI Safety Standard, which was followed by a Proposals Paper later in September of that year, outlining potential guardrails for high-risk AI that could become mandatory. These guardrails include areas such as model testing, transparency, human oversight, and record-keeping, all of which may be enforced through new legislation. As noted, however, Australia has not yet passed AI-specific laws, but existing statutes such as the Privacy Act 1988 , Corporations Act 2001 , and Online Safety Act 2021 all have applications which apply to AI use. [ 90 ] In September 2024, a bill also was introduced which granted the Australian Communications and Media Authority powers to regulate AI-generated misinformation. Several agencies, including the ACMA , ACCC , and Office of the Australian Information Commissioner , are all expected to play roles in future AI regulation. [ 90 ] Brazil On September 30, 2021, the Brazilian Chamber of Deputies (Câmara dos Deputados) approved the Brazilian Legal Framework for Artificial Intelligence (Marco Legal da Inteligência Artificial). This legislation aimed to regulate AI development and usage while promoting research and innovation in ethical AI solutions that prioritize culture, justice, fairness, and accountability. [ 91 ] The 10-article bill established several key objectives: developing ethical principles for AI, promoting sustained research investment, and removing barriers to innovation. Article 4 specifically emphasized preventing discriminatory AI solutions, ensuring plurality, and protecting human rights. When the bill was first released to the public, it faced substantial criticism, alarming the government for critical provisions. The underlying issue is that this bill failed to thoroughly and carefully address accountability, transparency, and inclusivity principles. Article VI establishes subjective liability, meaning any individual that is damaged by an AI system and is wishing to receive compensation must specify the stakeholder and prove that there was a mistake in the machine's life cycle. Scholars emphasize that it is out of legal order to assign an individual responsible for proving algorithmic errors given the high degree of autonomy, unpredictability, and complexity of AI systems. [ 92 ] This also drew attention to the currently occurring issues with face recognition systems in Brazil leading to unjust arrests by the police, which would then imply that when this bill is adopted, individuals would have to prove and justify these machine errors. The main controversy of this draft bill was directed to three proposed principles. First, the non-discrimination principle, [ 93 ] suggests that AI must be developed and used in a way that merely mitigates the possibility of abusive and discriminatory practices. Secondly, the pursuit of neutrality principle lists recommendations for stakeholders to mitigate biases; however, with no obligation to achieve this goal. Lastly, the transparency principle states that a system's transparency is only necessary when there is a high risk of violating fundamental rights. As easily observed, the Brazilian Legal Framework for Artificial Intelligence lacks binding and obligatory clauses and is rather filled with relaxed guidelines. In fact, experts emphasize that this bill may even make accountability for AI discriminatory biases even harder to achieve. Compared to the EU's proposal of extensive risk-based regulations, the Brazilian Bill has 10 articles proposing vague and generic recommendations. The Brazilian AI Bill lacks the diverse perspectives that characterized earlier Brazilian internet legislation. When Brazil drafted the Marco Civil da Internet (Brazilian Internet Bill of Rights) in the 2000s, it used a multistakeholder approach that brought together various groups—including government, civil society, academia, and industry—to participate in dialogue, decision-making, and implementation. This collaborative process helps capture different viewpoints and trade-offs among stakeholders with varying interests, ultimately improving transparency and effectiveness in AI regulation. [ 92 ] In May 2023, a new bill was passed, superseding the 2021 bill. It calls for risk assessments of AI systems before deployment and distinguishes \"high risk\" and \"excessive risk\" systems. The latter are characterized by their potential to expose or exploit vulnerabilities and will be subject to regulation by the Executive Branch. [ 94 ] Canada The Pan-Canadian Artificial Intelligence Strategy (2017) is supported by federal funding of Can $125 million with the objectives of increasing the number of outstanding AI researchers and skilled graduates in Canada, establishing nodes of scientific excellence at the three major AI centres, developing 'global thought leadership' on the economic, ethical, policy and legal implications of AI advances and supporting a national research community working on AI. [ 64 ] The Canada CIFAR AI Chairs Program is the cornerstone of the strategy. It benefits from funding of Can$86.5 million over five years to attract and retain world-renowned AI researchers. [ 64 ] The federal government appointed an Advisory Council on AI in May 2019 with a focus on examining how to build on Canada's strengths to ensure that AI advancements reflect Canadian values, such as human rights, transparency and openness. The Advisory Council on AI has established a working group on extracting commercial value from Canadian-owned AI and data analytics. [ 64 ] In 2020, the federal government and Government of Quebec announced the opening of the International Centre of Expertise in Montréal for the Advancement of Artificial Intelligence, which will advance the cause of responsible development of AI. [ 64 ] In June 2022, the government of Canada started a second phase of the Pan-Canadian Artificial Intelligence Strategy. [ 95 ] In November 2022, Canada has introduced the Digital Charter Implementation Act (Bill C-27), which proposes three acts that have been described as a holistic package of legislation for trust and privacy: the Consumer Privacy Protection Act, the Personal Information and Data Protection Tribunal Act, and the Artificial Intelligence &amp; Data Act (AIDA). [ 96 ] [ 97 ] In September 2023, the Canadian Government introduced a Voluntary Code of Conduct for the Responsible Development and Management of Advanced Generative AI Systems. The code, based initially on public consultations, seeks to provide interim guidance to Canadian companies on responsible AI practices. Ultimately, its intended to serve as a stopgap until formal legislation, such as the Artificial Intelligence and Data Act (AIDA), is enacted. [ 98 ] [ 99 ] Moreover, in November 2024, the Canadian government additionally announced the creation of the Canadian Artificial Intelligence Safety Institute (CAISI) as part of a 2.4 billion CAD federal AI investment package. This includes 2 billion CAD to support a new AI Sovereign Computing Strategy and the AI Computing Access Fund, which aims to bolster Canada's advanced computing infrastructure. Further funding includes 700 million CAD for domestic AI development, 1 billion CAD for public supercomputing infrastructure, and 300 million CAD to assist companies in accessing new AI resources. [ 99 ] China Further information: Artificial intelligence industry in China The regulation of AI in China is mainly governed by the State Council of the People's Republic of China 's July 8, 2017 \"A Next Generation Artificial Intelligence Development Plan\" (State Council Document No. 35), in which the Central Committee of the Chinese Communist Party and the State Council of the PRC urged the governing bodies of China to promote the development of AI up to 2030. Regulation of the issues of ethical and legal support for the development of AI is accelerating, and policy ensures state control of Chinese companies and over valuable data, including storage of data on Chinese users within the country and the mandatory use of People's Republic of China's national standards for AI, including over big data, cloud computing, and industrial software. [ 100 ] [ 101 ] [ 102 ] In 2021, China published ethical guidelines for the use of AI in China which state that researchers must ensure that AI abides by shared human values, is always under human control, and is not endangering public safety. [ 103 ] In 2023, China introduced Interim Measures for the Management of Generative AI Services . [ 104 ] On August 15, 2023, China's first generative AI measures officially came into force, becoming one of the first comprehensive national regulatory frameworks for generative AI. The measures apply to all providers offering generative AI services to the Chinese public, including foreign entities, ultimately setting the rules related to data protection, transparency, and algorithmic accountability. [ 105 ] [ 106 ] In parallel, earlier regulations such as the Chinese government's Deep Synthesis Provisions (effective January 2023) and the Algorithm Recommendation Provisions (effective March 2022) continue to shape China's governance of AI-driven systems, including requirements for watermarking and algorithm filing with the Cyberspace Administration of China (CAC). [ 107 ] Additionally, In October 2023, China also implemented a set of Ethics Review Measures for science and technology, mandating certain ethical assessments of AI projects which were deemed deemed socially sensitive or capable of negatively influencing public opinion. [ 105 ] As of mid-2024, over 1,400 AI algorithms had been already registered under the CAC 's algorithm filing regime, which includes disclosure requirements and penalties for noncompliance. [ 105 ] This layered approach reflects a broader policy process shaped by not only central directives but also academic input, civil society concerns, and public discourse. [ 107 ] Colombia Although Colombia has not issued specific AI laws, this does not mean there is a lack of frameworks or initiatives to govern it. In fact, there are numerous instruments issued for that purpose, including national policies, ethical frameworks, roadmaps, rulings, and guidelines. In addition, there are other existing regulations applicable to AI systems, such as data protection, intellectual property, consumer laws, and civil liability rules. One of the first specific instruments issued was the CONPES 3920 of 2019, the National Policy on Exploitation of Data (Big Data). The main purpose of this policy was to leverage data in Colombia by creating the conditions to handle it as an asset to generate social and economic value. [ 108 ] Another milestone occurred in 2021, when the National Government published the Ethical Framework for AI in Colombia. It was a soft law guide for public entities, offering recommendations to consider in the management of AI-related projects. [ 109 ] An additional framework for AI was adopted by Colombia in 2022: the Recommendation on the Ethics of Artificial Intelligence by UNESCO. [ 109 ] It includes values and principles applicable in the public and private sectors in all stages of the AI system life cycle. [ 109 ] A regional political commitment on AI was made in 2023, involving Latin American and Caribbean countries. It was called the Declaration of Santiago, whose main purpose is to promote ethical AI in the region. [ 110 ] 2024 was a prolific year in governing AI in Colombia. A roadmap for an ethical and sustainable AI adoption was launched by the National Government. [ 111 ] The Superintendence of Industry and Commerce issued a guide on the processing of personal data in AI systems. [ 112 ] The Judiciary Council published a guideline for the use of AI in the judicial sector. [ 113 ] In the global context, the OECD principles were updated, [ 114 ] the Global Digital Compact by the United Nations was published, [ 115 ] and the UN adopted Resolution A/78/L.49 on safe, trustworthy, and reliable AI systems for sustainable development. [ 116 ] In 2025, a new national policy on AI was issued by the National Government, contained in CONPES 4144. [ 117 ] The ruling T-067/25 by the Constitutional Court provided some rules for access to public information and transparency of algorithms. [ 118 ] Until Congress issues AI regulations, these soft-law documents can guide the design, development, and use of AI systems in Colombia. Council of Europe The Council of Europe (CoE) is an international organization that promotes human rights, democracy and the rule of law. It comprises 46 member states, including all 29 Signatories of the European Union's 2018 Declaration of Cooperation on Artificial Intelligence. The CoE has created a common legal space in which the members have a legal obligation to guarantee rights as set out in the European Convention on Human Rights . Specifically in relation to AI, \"The Council of Europe's aim is to identify intersecting areas between AI and our standards on human rights, democracy and rule of law, and to develop relevant standard setting or capacity-building solutions\". The large number of relevant documents identified by the CoE include guidelines, charters, papers, reports and strategies. [ 119 ] The authoring bodies of these AI regulation documents are not confined to one sector of society and include organizations, companies, bodies and nation-states. [ 71 ] In 2019, the Council of Europe initiated a process to assess the need for legally binding regulation of AI, focusing specifically on its implications for human rights and democratic values. Negotiations on a treaty began in September 2022, involving the 46 member states of the Council of Europe, as well as Argentina, Australia, Canada, Costa Rica, the Holy See, Israel, Japan, Mexico, Peru, the United States of America, and Uruguay, as well as the European Union. On 17 May 2024, the \" Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law \" was adopted. It was opened for signature on 5 September 2024. Although developed by a European organisation, the treaty is open for accession by states from other parts of the world. The first ten signatories were: Andorra, Georgia, Iceland, Norway, Moldova, San Marino, the United Kingdom, Israel, the United States, and the European Union. [ 120 ] [ 121 ] Czech Republic The Czech Republic adopted a National AI Strategy in 2019 and updated it in 2024 with the National AI Strategy of the Czech Republic 2030. [ 122 ] The updated strategy includes a provision to ensure effective legislation, to create codes of ethics for developers and users, to establish supervisory bodies and to promote the ethical use of AI. [ 123 ] European Union Main article: Artificial Intelligence Act The EU is one of the largest jurisdictions in the world and plays an active role in the global regulation of digital technology through the GDPR , [ 124 ] Digital Services Act , and the Digital Markets Act . [ 125 ] [ 126 ] For AI in particular, the Artificial intelligence Act is regarded in 2023 as the most far-reaching regulation of AI worldwide. [ 127 ] [ 128 ] Most European Union (EU) countries have their own national strategies towards regulating AI, but these are largely convergent. [ 71 ] The European Union is guided by a European Strategy on Artificial Intelligence, [ 129 ] supported by a High-Level Expert Group on Artificial Intelligence. [ 130 ] [ 131 ] In April 2019, the European Commission published its Ethics Guidelines for Trustworthy Artificial Intelligence (AI) , [ 132 ] following this with its Policy and investment recommendations for trustworthy Artificial Intelligence in June 2019. [ 133 ] The EU Commission's High Level Expert Group on Artificial Intelligence carries out work on Trustworthy AI, and the commission has issued reports on the Safety and Liability Aspects of AI and on the Ethics of Automated Vehicles. In 2020. the EU Commission sought views on a proposal for AI specific legislation, and that process is ongoing. [ 71 ] On February 2, 2020, the European Commission published its White Paper on Artificial Intelligence – A European approach to excellence and trust . [ 134 ] [ 135 ] The White Paper consists of two main building blocks, an 'ecosystem of excellence' and a 'ecosystem of trust'. The 'ecosystem of trust' outlines the EU's approach for a regulatory framework for AI. In its proposed approach, the Commission distinguishes AI applications based on whether they are 'high-risk' or not. Only high-risk AI applications should be in the scope of a future EU regulatory framework. An AI application is considered high-risk if it operates in a risky sector (such as healthcare, transport or energy) and is \"used in such a manner that significant risks are likely to arise\". For high-risk AI applications, the requirements are mainly about the : \"training data\", \"data and record-keeping\", \"information to be provided\", \"robustness and accuracy\", and \"human oversight\". There are also requirements specific to certain usages such as remote biometric identification. AI applications that do not qualify as 'high-risk' could be governed by a voluntary labeling scheme. As regards compliance and enforcement, the Commission considers prior conformity assessments which could include 'procedures for testing, inspection or certification' and/or 'checks of the algorithms and of the data sets used in the development phase'. A European governance structure on AI in the form of a framework for cooperation of national competent authorities could facilitate the implementation of the regulatory framework. [ 136 ] A January 2021 draft was leaked online on April 14, 2021, [ 137 ] before the Commission presented their official \"Proposal for a Regulation laying down harmonised rules on artificial intelligence\" a week later. [ 138 ] Shortly after, the Artificial Intelligence Act (also known as the AI Act) was formally proposed on this basis. [ 139 ] This proposal includes a refinement of the 2020 risk-based approach with, this time, 4 risk categories: \"minimal\", \"limited\", \"high\" and \"unacceptable\". [ 140 ] The proposal has been severely critiqued in the public debate. Academics have expressed concerns about various unclear elements in the proposal – such as the broad definition of what constitutes AI – and feared unintended legal implications, especially for vulnerable groups such as patients and migrants. [ 141 ] [ 142 ] The risk category \"general-purpose AI\" was added to the AI Act to account for versatile models like ChatGPT , which did not fit the application-based regulation framework. [ 143 ] Unlike for other risk categories, general-purpose AI models can be regulated based on their capabilities, not just their uses. Weaker general-purpose AI models are subject transparency requirements, while those considered to pose \"systemic risks\" (notably those trained using computational capabilities exceeding 10 25 FLOPS ) must also undergo a thorough evaluation process. [ 144 ] A subsequent version of the AI Act was finally adopted in May 2024. [ 145 ] The AI Act will be progressively enforced. [ 146 ] Recognition of emotions and real-time remote biometric identification will be prohibited, with some exemptions, such as for law enforcement. [ 147 ] The European Union's AI Act has created a regulatory framework with significant global implications. This legislation introduces a risk-based approach to categorizing AI systems, focusing on high-risk applications like healthcare, education, and public safety. [ 148 ] It requires organizations to ensure transparency, data governance, and human oversight in their AI solutions. While this aims to foster ethical AI use, the stringent requirements could increase overhead and compliance costs, delaying certain AI designs and deployments. [ 149 ] [ 150 ] [ 151 ] Observers have expressed concerns about the multiplication of legislative proposals under the von der Leyen Commission . The speed of the legislative initiatives is partially led by political ambitions of the EU and could put at risk the digital rights of the European citizens, including rights to privacy, [ 152 ] especially in the face of uncertain guarantees of data protection through cyber security. [ 131 ] Among the stated guiding principles in the variety of legislative proposals in the area of AI under the von der Leyen Commission are the objectives of strategic autonomy [ 153 ] and the concept of digital sovereignty. [ 154 ] On May 29, 2024, the European Court of Auditors published a report stating that EU measures were not well coordinated with those of EU countries; that the monitoring of investments was not systematic; and that stronger governance was needed. [ 155 ] The EU's Artificial Intelligence Act (Regulation (EU) 2024/1689) entered into force on 1 August 2024, creating a risk-based legal framework for AI systems, including special provisions for general-purpose AI models enforceable by 2 August 2025. [ 156 ] Finland Finland has appointed a working group to evaluate what national legislation is required by the EU Artificial intelligence Act , and to prepare a legislative proposal on its national implementation. The working group began its evaluation on April 29, 2024, and is expected to conclude by June 30, 2026. [ 157 ] Germany In November 2020, [ 158 ] DIN , DKE and the German Federal Ministry for Economic Affairs and Energy published the first edition of the \"German Standardization Roadmap for Artificial Intelligence\" (NRM KI) and presented it to the public at the Digital Summit of the Federal Government of Germany. [ 159 ] NRM KI describes requirements to future regulations and standards in the context of AI. The implementation of the recommendations for action is intended to help to strengthen the German economy and science in the international competition in the field of artificial intelligence and create innovation-friendly conditions for this emerging technology . The first edition is a 200-page long document written by 300 experts. The second edition of the NRM KI was published to coincide with the German government's Digital Summit on December 9, 2022. [ 160 ] DIN coordinated more than 570 participating experts from a wide range of fields from science, industry, civil society and the public sector. The second edition is a 450-page long document. On the one hand, NRM KI covers the focus topics in terms of applications (e.g. medicine, mobility, energy &amp; environment, financial services, industrial automation) and fundamental issues (e.g. AI classification, security, certifiability, socio-technical systems, ethics). [ 160 ] On the other hand, it provides an overview of the central terms in the field of AI and its environment across a wide range of interest groups and information sources. In total, the document covers 116 standardisation needs and provides six central recommendations for action. [ 161 ] G7 On 30 October 2023, members of the G7 subscribe to eleven guiding principles for the design, production and implementation of advanced artificial intelligence systems, as well as a voluntary Code of Conduct for artificial intelligence developers in the context of the Hiroshima Process. [ 162 ] The agreement receives the applause of Ursula von der Leyen who finds in it the principles of the AI Directive, then being finalized. New guidelines also aim to establish a coordinated global effort towards the responsible development and use of advanced AI systems. While non-binding, the G7 governments encourage organizations to voluntarily adopt the guidelines, which emphasize a risk-based approach across the AI lifecycle—from pre-deployment risk assessment to post-deployment incident reporting and mitigation. [ 163 ] The AIP&amp;CoC also highlight the importance of AI system security, internal adversarial testing ('red teaming'), public transparency about capabilities and limitations, and governance procedures that include privacy safeguards and content authentication tools. The guidelines additionally promote AI innovation directed at solving global challenges such as climate change and public health, and call for advancing international technical standards. [ 163 ] Looking ahead, the G7 intends to further refine their principles and Code of Conduct in collaboration with other organizations like the OECD , GPAI , and broader stakeholders. Areas of broader development include more clrsnrt AI terminology (e.g., \"advanced AI systems\"), the setting of risk benchmarks, and mechanisms for cross-border information sharing on potential AI risks. Despite general alignment on AI safety, analysts have noted that differing regulatory philosophies—such as the EU's prescriptive AI Act versus the U.S.'s sector-specific approach—may challenge global regulatory harmonization. [ 164 ] Israel On October 30, 2022, pursuant to government resolution 212 of August 2021, the Israeli Ministry of Innovation, Science and Technology released its \"Principles of Policy, Regulation and Ethics in AI\" white paper for public consultation. [ 165 ] By December 2023, the Ministry of Innovation and the Ministry of Justice published a joint AI regulation and ethics policy paper, outlining several AI ethical principles and a set of recommendations including opting for sector-based regulation, a risk-based approach, preference for \"soft\" regulatory tools and maintaining consistency with existing global regulatory approaches to AI. [ 166 ] In December 2023, Israel unveiled its first comprehensive national AI policy, which was jointly developed through a collaboration between ministerial and stakeholder consultation. In general, the new policy outlines ethical principles aligned with current OECD guidelines and recommends a sector-based, risk-driven regulatory framework, which focuses on areas like transparency and accountability. [ 167 ] The policy proposes the creation of a national AI Policy Coordination Center to support regulators, and further developing the tools necessary for responsible AI deployment. In addition, alongside 56 other nations, to domestic policy development, Israel signed the world's first binding international treaty on artificial intelligence in March 2024. The specific treaty, led by the Council of Europe , has obliged signatories to ensure current AI systems uphold democratic values, human rights, and the rule of law. [ 168 ] Italy In October 2023, the Italian privacy authority approved a regulation that provides three principles for therapeutic decisions taken by automated systems: transparency of decision-making processes, human supervision of automated decisions and algorithmic non-discrimination. [ 169 ] In March 2024, the President of the Italian Data Protection Authority reaffirmed their agency's readiness to implement the European Union's newly introduced Artificial Intelligence Act , praising the framework of institutional competence and independence. [ 170 ] Italy has continued to develop guidance on AI applications through existing legal frameworks, including ",
  "cached_at": "2025-10-25T19:37:51.434322"
}