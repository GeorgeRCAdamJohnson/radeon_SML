{
  "title": "Laws of robotics",
  "summary": "Laws of robotics are any set of laws, rules, or principles, which are intended as a fundamental framework to underpin the behavior of robots designed to have a degree of autonomy. Robots of this degree of complexity do not yet exist, but they have been widely anticipated in science fiction, films and are a topic of active research and development in the fields of robotics and artificial intelligence",
  "content": "Laws of robotics Robotics body.skin-minerva body.skin--responsive Laws of robotics Isaac Asimov Three Laws of Robotics in popular culture Related topics Roboethics Ethics of AI Machine ethics html.skin-theme-clientpref-night v t e Laws of robotics are any set of laws, rules, or principles, which are intended as a fundamental framework to underpin the behavior of robots designed to have a degree of autonomy . Robots of this degree of complexity do not yet exist, but they have been widely anticipated in science fiction , films and are a topic of active research and development in the fields of robotics and artificial intelligence . The best known set of laws are those written by Isaac Asimov in the 1940s, or based upon them, but other sets of laws have been proposed by researchers in the decades since then. Isaac Asimov's Three Laws of Robotics Main article: Three Laws of Robotics The best known set of laws are Isaac Asimov 's Three Laws of Robotics . These were introduced in his 1942 short story Runaround , although they were foreshadowed in a few earlier stories. The Three Laws are: A robot may not injure a human being or, through inaction, allow a human being to come to harm. A robot must obey the orders given it by human beings except where such orders would conflict with the First Law. A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws. 1 In The Evitable Conflict the machines generalize the First Law to mean: No machine may harm humanity; or, through inaction, allow humanity to come to harm. This was refined in the end of Foundation and Earth . A zeroth law was introduced, with the original three suitably rewritten as subordinate to it: A robot may not injure humanity, or, by inaction, allow humanity to come to harm. Adaptations and extensions exist based upon this framework. As of 2024 update they remain a fictional device . 2 Additional laws Authors other than Asimov have often created extra laws. The 1974 Lyuben Dilov novel, Icarus's Way (a.k.a., The Trip of Icarus ) introduced a Fourth Law of robotics: A robot must establish its identity as a robot in all cases. Dilov gives reasons for the fourth safeguard in this way: The last Law has put an end to the expensive aberrations of designers to give psychorobots as humanlike a form as possible. And to the resulting misunderstandings... . 3 More formally, in 2024 Dariusz Jemielniak in an article in IEEE Spectrum proposed a Fourth Law of Robotics: A robot or AI must not deceive a human by impersonating a human being. 4 5 6 7 8 A fifth law was introduced by Nikola Kesarovski in his short story The Fifth Law of Robotics . This fifth law says: A robot must know it is a robot. The plot revolves around a murder where the forensic investigation discovers that the victim was killed by a hug from a humaniform robot that did not establish for itself that it was a robot. 9 The story was reviewed by Valentin D. Ivanov in SFF review webzine The Portal . 10 For the 1986 tribute anthology, Foundation's Friends , Harry Harrison wrote a story entitled, The Fourth Law of Robotics . This Fourth Law states: A robot must reproduce. As long as such reproduction does not interfere with the First or Second or Third Law. In 2013 Hutan Ashrafian proposed an additional law that considered the role of artificial intelligence-on-artificial intelligence or the relationship between robots themselves – the so-called AIonAI law. 11 This sixth law states: All robots endowed with comparable human reason and conscience should act towards one another in a spirit of brotherhood. EPSRC / AHRC principles of robotics In 2011, the Engineering and Physical Sciences Research Council (EPSRC) and the Arts and Humanities Research Council (AHRC) of United Kingdom jointly published a set of five ethical principles for designers, builders and users of robots in the real world , along with seven high-level messages intended to be conveyed, based on a September 2010 research workshop: 2 12 13 Robots should not be designed solely or primarily to kill or harm humans. Humans, not robots, are responsible agents. Robots are tools designed to achieve human goals. Robots should be designed in ways that assure their safety and security. Robots are artifacts; they should not be designed to exploit vulnerable users by evoking an emotional response or dependency. It should always be possible to tell a robot from a human. It should always be possible to find out who is legally responsible for a robot. The messages intended to be conveyed were: We believe robots have the potential to provide immense positive impact to society. We want to encourage responsible robot research. Bad practice hurts us all. Addressing obvious public concerns will help us all make progress. It is important to demonstrate that we, as roboticists, are committed to the best possible standards of practice. To understand the context and consequences of our research, we should work with experts from other disciplines, including: social sciences, law, philosophy and the arts. We should consider the ethics of transparency: are there limits to what should be openly available? When we see erroneous accounts in the press, we commit to take the time to contact the reporting journalists. The EPSRC principles are broadly recognised as a useful starting point. In 2016 Tony Prescott organised a workshop to revise these principles, e.g. to differentiate ethical from legal principles. 14 Judicial development Another comprehensive terminological codification for the legal assessment of the technological developments in the robotics industry has already begun mainly in Asian countries. 15 This progress represents a contemporary reinterpretation of the law (and ethics) in the field of robotics, an interpretation that assumes a rethinking of traditional legal constellations. These include primarily legal liability issues in civil and criminal law. Satya Nadella's laws In June 2016, Satya Nadella , the CEO of Microsoft Corporation , had an interview with the Slate magazine and reflected on what kinds of principles and goals should be considered by industry and society when discussing artificial intelligences: 16 17 A.I. must be designed to assist humanity , meaning human autonomy needs to be respected. A.I. must be transparent meaning that humans should know and be able to understand how they work. A.I. must maximize efficiencies without destroying the dignity of people. A.I. must be designed for intelligent privacy meaning that it earns trust through guarding their information. A.I. must have algorithmic accountability so that humans can undo unintended harm. A.I. must guard against bias so that they must not discriminate against people. Tilden's laws Mark W. Tilden is a robotics physicist who was a pioneer in developing simple robotics. 18 Tilden later disparaged his earlier work as wimpy for having been based on the human-centric Asimov laws. He created three new guiding principles/rules for wild robots: 18 19 20 A robot must protect its existence at all costs. A robot must obtain and maintain access to its own power source. A robot must continually search for better power sources. Within these three rules for wild life, Tilden is basically stating his goal as: ...proctoring a silicon species into sentience, but with full control over the specs. Not plant. Not animal. Something else. 21 See also Friendly AI Roboethics Ethics of artificial intelligence Military robots which may be designed such that they violate Asimov's First Law. Three Laws of Transhumanism Clarke's three laws Niven's laws References ↑ body:not(.skin-timeless):not(.skin-minerva) Asimov, Isaac (1950). I, Robot . 1 2 Stewart, Jon (2011-10-03). Ready for the robot revolution? . BBC News . Retrieved 2011-10-03 . ↑ Dilov, Lyuben (aka Lyubin, Luben or Liuben) (2002). Пътят на Икар . Захари Стоянов. ISBN 978-954-739-338-7 . : CS1 maint: multiple names: authors list ( link ) ↑ We Need a Fourth Law of Robotics for AI - IEEE Spectrum . spectrum.ieee.org . Retrieved 2025-02-03 . ↑ A Fourth Law of Robotics | Berkman Klein Center . cyber.harvard.edu . 2025-01-24 . Retrieved 2025-02-03 . ↑ Ki kell egészíteni Asimov robotikai törvényeit az AI miatt . Blikk (in Hungarian). 2025-01-15 . Retrieved 2025-02-03 . ↑ Tecnológica, Site Inovação (2025-01-21). Leis da Robótica de Asimov precisam de atualização para IA . Site Inovação Tecnológica (in Portuguese) . Retrieved 2025-02-03 . ↑ Jaśkowiak, Piotr (2025-02-01). Asimovowi zabrakło wyobraźni. Potrzebujemy Czwartego Prawa Robotyki . Radio TokFM . ↑ Кесаровски, Никола (1983). Петият закон . Отечество. ↑ ,, ' /> Lawful Little Country: The Bulgarian Laws of Robotics | The Portal . Archived from the original on 2011-10-06 . Retrieved 2023-02-08 . ↑ Ashrafian, Hutan (2014). AIonAI: A Humanitarian Law of Artificial Intelligence and Robotics . Science and Engineering Ethics . 21 (1): 29– 40. doi : 10.1007/s11948-013-9513-9 . PMID 24414678 . S2CID 2821971 . ↑ Principles of robotics: Regulating Robots in the Real World . Engineering and Physical Sciences Research Council . Retrieved 2011-10-03 . ↑ Winfield, Alan. Five roboethical principles – for humans . New Scientist . Retrieved 2011-10-03 . ↑ Müller, Vincent C. (2017). Legal vs. ethical obligations – a comment on the EPSRC's principles for robotics . Connection Science . 29 (2): 137– 141. Bibcode : 2017ConSc..29..137M . doi : 10.1080/09540091.2016.1276516 . S2CID 19080722 . ↑ bcc.co.uk: Robot age poses ethical dilemma. Link ↑ Nadella, Satya (2016-06-28). The Partnership of the Future . Slate . ISSN 1091-2339 . Retrieved 2016-06-30 . ↑ Vincent, James (2016-06-29). Satya Nadella's rules for AI are more boring (and relevant) than Asimov's Three Laws . The Verge . Vox Media . Retrieved 2016-06-30 . 1 2 Hapgood, Fred (September 1994). Chaotic Robotics . Wired . Vol. 2, no. 9. ↑ Dunn, Ashley (1996-06-05). Machine Intelligence, Part II: From Bumper Cars to Electronic Minds . The New York Times . Retrieved 2009-07-26 . ↑ ,, ' /> makezine.com: A Beginner's Guide to BEAM . (Most of the article is subscription-only content.) ↑ Hapgood, Fred (September 1994). Chaotic Robotics (continued) . Wired . Vol. 2, no. 9. 1 body.skin--responsive v t e Robotics Main articles Outline Glossary Index History Geography Hall of Fame Ethics Laws Competitions AI competitions Types Aerobot Anthropomorphic Humanoid Android Cyborg Gynoid Claytronics Companion Automaton Animatronic Audio-Animatronics Industrial Articulated arm Domestic Educational Entertainment Juggling Military Medical Service Disability Agricultural Food service Retail BEAM robotics Soft robotics Classifications Biorobotics Cloud robotics Continuum robot Unmanned vehicle aerial ground Mobile robot Microbotics Nanorobotics Necrobotics Robotic spacecraft Space probe Swarm Telerobotics Underwater remotely-operated Robotic fish Locomotion Tracks Walking Hexapod Climbing Electric unicycle Robotic fins Navigation and mapping Motion planning Simultaneous localization and mapping Visual odometry Vision-guided robot systems Research Evolutionary Kits Simulator Suite Open-source Software Adaptable Developmental Human–robot interaction Paradigms Perceptual Situated Ubiquitous Companies ABB Amazon Robotics Anybots Barrett Technology Boston Dynamics Doosan Robotics Energid Technologies FarmWise FANUC Figure AI Foster-Miller Harvest Automation HD Hyundai Robotics Honeybee Robotics Intuitive Surgical IRobot KUKA Rainbow Robotics Starship Technologies Symbotic Universal Robotics Wolf Robotics Yaskawa Related Critique of work Powered exoskeleton Workplace robotics safety Robotic tech vest Technological unemployment Terrainability Fictional robots Category Outline ↑ 17. Announcer (2011). Portal 2",
  "cached_at": "2025-10-25T20:04:51.780900"
}