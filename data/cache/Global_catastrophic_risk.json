{
  "title": "Global catastrophic risk",
  "summary": "A global catastrophic risk or a doomsday scenario is a hypothetical event that could damage human well-being on a global scale, endangering or even destroying modern civilization. Existential risk is a related term limited to events that could cause full-blown human extinction or permanently and drastically curtail humanity's existence or potential",
  "content": "Global catastrophic risk Hypothetical global-scale disaster risk Doomsday scenario redirects here. For other uses, see Doomsday (disambiguation) . Not to be confused with Global Catastrophic Risks (book) . For broader coverage of this topic, see Human extinction and Global catastrophe scenarios . Artist's impression of a major asteroid impact . An asteroid caused the extinction of the non-avian dinosaurs . 1 body.skin-minerva body.skin--responsive Futures studies Concepts Accelerating change Cashless society Global catastrophic risk Future Earth Mathematics Race Climate Space exploration Universe Historical materialism Kondratiev wave Kardashev scale Moore's law Peak oil Population cycle Resource depletion Singularity Swanson's law Techniques Backcasting Causal layered analysis Chain-linked model Consensus forecast Cross impact analysis Delphi Real-time Delphi Foresight Future-proof Futures wheel Future workshop Horizon scanning Reference class forecasting Scenario planning Systems analysis Threatcasting Trend analysis Technology assessment and forecasting Critical design Design fiction Exploratory engineering FTA Hype cycle Science fiction prototyping Speculative design TRL Technology scouting Related topics Futarchy Transhumanism html.skin-theme-clientpref-night v t e A global catastrophic risk or a doomsday scenario is a hypothetical event that could damage human well-being on a global scale, 2 endangering or even destroying modern civilization . 3 Existential risk is a related term limited to events that could cause full-blown human extinction or permanently and drastically curtail humanity's existence or potential. 4 In the 21st century, a number of academic and non-profit organizations have been established to research global catastrophic and existential risks, formulate potential mitigation measures, and either advocate for or implement these measures. Definition and classification Scope–severity grid from Bostrom's paper Existential Risk Prevention as Global Priority 5 Defining global catastrophic risks The term global catastrophic risk lacks a sharp definition , and generally refers (loosely) to a risk that could inflict serious damage to human well-being on a global scale . 6 Humanity has suffered large catastrophes before. Some of these have caused serious damage but were only local in scope—e.g. the Black Death may have resulted in the deaths of a third of Europe's population, 7 10% of the global population at the time. 8 Some were global, but were not as severe—e.g. the 1918 influenza pandemic killed an estimated 3–6% of the world's population. 9 Most global catastrophic risks would not be so intense as to kill the majority of life on earth, but even if one did, the ecosystem and humanity would eventually recover (in contrast to existential risks ). Similarly, in Catastrophe: Risk and Response , Richard Posner singles out and groups together events that bring about utter overthrow or ruin on a global, rather than a local or regional scale. Posner highlights such events as worthy of special attention on cost–benefit grounds because they could directly or indirectly jeopardize the survival of the human race as a whole. 10 Defining existential risks Existential risks are defined as risks that threaten the destruction of humanity's long-term potential. 11 The instantiation of an existential risk (an existential catastrophe 12 ) would either cause outright human extinction or irreversibly lock in a drastically inferior state of affairs. 5 13 Existential risks are a sub-class of global catastrophic risks, where the damage is not only global but also terminal and permanent, preventing recovery and thereby affecting both current and all future generations. 5 Non-extinction risks While extinction is the most obvious way in which humanity's long-term potential could be destroyed, there are others, including unrecoverable collapse and unrecoverable dystopia . 14 A disaster severe enough to cause the permanent, irreversible collapse of human civilisation would constitute an existential catastrophe, even if it fell short of extinction. 14 Similarly, if humanity fell under a totalitarian regime, and there were no chance of recovery, then such a dystopia would also be an existential catastrophe. 15 Bryan Caplan writes that perhaps an eternity of totalitarianism would be worse than extinction . 15 ( George Orwell 's novel Nineteen Eighty-Four suggests 16 an example. 17 ) A dystopian scenario shares the key features of extinction and unrecoverable collapse of civilization: before the catastrophe humanity faced a vast range of bright futures to choose from; after the catastrophe, humanity is locked forever in a terrible state. 14 Potential sources of risk Main article: Global catastrophe scenarios Potential global catastrophic risks are conventionally classified as anthropogenic or non-anthropogenic hazards. Examples of non-anthropogenic risks are an asteroid or comet impact event , a supervolcanic eruption , a natural pandemic , a lethal gamma-ray burst , a geomagnetic storm from a coronal mass ejection destroying electronic equipment, natural long-term climate change , hostile extraterrestrial life , or the Sun transforming into a red giant star and engulfing the Earth billions of years in the future . 18 Arrangement of global catastrophic risks into three sets according to whether they are largely human-caused, human influences upon nature, or purely natural Anthropogenic risks are those caused by humans and include those related to technology, governance, and climate change. Technological risks include the creation of artificial intelligence misaligned with human goals, biotechnology , and nanotechnology . Insufficient or malign global governance creates risks in the social and political domain, such as global war and nuclear holocaust , 19 biological warfare and bioterrorism using genetically modified organisms , cyberwarfare and cyberterrorism destroying critical infrastructure like the electrical grid , or radiological warfare using weapons such as large cobalt bombs . Other global catastrophic risks include climate change, environmental degradation , extinction of species , famine as a result of non-equitable resource distribution, human overpopulation or underpopulation , crop failures , and non- sustainable agriculture . Methodological challenges Research into the nature and mitigation of global catastrophic risks and existential risks is subject to a unique set of challenges and, as a result, is not easily subjected to the usual standards of scientific rigour. 14 For instance, it is neither feasible nor ethical to study these risks experimentally. Carl Sagan expressed this with regards to nuclear war: Understanding the long-term consequences of nuclear war is not a problem amenable to experimental verification . 20 Moreover, many catastrophic risks change rapidly as technology advances and for example, Medieval Europe survived the Black Death without suffering anything resembling a civilization collapse despite losing 25 to 50 percent of its population. 24 Incentives and coordination There are economic reasons that can explain why so little effort is going into global catastrophic risk reduction. First, it is speculative and may never happen, so many people focus on other more pressing issues. It is also a global public good , so we should expect it to be undersupplied by markets. 5 Even if a large nation invested in risk mitigation measures, that nation would enjoy only a small fraction of the benefit of doing so. Furthermore, global catastrophic risk reduction can be thought of as an intergenerational global public good. Since most of the hypothetical benefits of the reduction would be enjoyed by future generations, and though these future people would perhaps be willing to pay substantial sums for risk reduction, no mechanism for such a transaction exists. 5 Cognitive biases Numerous cognitive biases can influence people's judgment of the importance of existential risks, including scope insensitivity , hyperbolic discounting , the availability heuristic , the conjunction fallacy , the affect heuristic , and the overconfidence effect . 25 Scope insensitivity influences how bad people consider the extinction of the human race to be. For example, when people are motivated to donate money to altruistic causes, the quantity they are willing to give does not increase linearly with the magnitude of the issue: people are roughly as willing to prevent the deaths of 200,000 or 2,000 birds. 26 Similarly, people are often more concerned about threats to individuals than to larger groups. 25 Eliezer Yudkowsky theorizes that scope neglect plays a role in public perception of existential risks: 27 28 Substantially larger numbers, such as 500 million deaths, and especially qualitatively different scenarios such as the extinction of the entire human species, seem to trigger a different mode of thinking... People who would never dream of hurting a child hear of existential risk, and say, Well, maybe the human species doesn't really deserve to survive . All past predictions of human extinction have proven to be false. To some, this makes future warnings seem less credible. Nick Bostrom argues that the absence of human extinction in the past is weak evidence that there will be no human extinction in the future, due to survivor bias and other anthropic effects . 29 Sociobiologist E. O. Wilson argued that: The reason for this myopic fog, evolutionary biologists contend, is that it was actually advantageous during all but the last few millennia of the two million years of existence of the genus Homo... A premium was placed on close attention to the near future and early reproduction, and little else. Disasters of a magnitude that occur only once every few centuries were forgotten or transmuted into myth. 30 Proposed mitigation Multi-layer defense Defense in depth is a useful framework for categorizing risk mitigation measures into three layers of defense: 31 Prevention : Reducing the probability of a catastrophe occurring in the first place. Example: Measures to prevent outbreaks of new highly infectious diseases. Response : Preventing the scaling of a catastrophe to the global level. Example: Measures to prevent escalation of a small-scale nuclear exchange into an all-out nuclear war. Resilience : Increasing humanity's resilience (against extinction) when faced with global catastrophes. Example: Measures to increase food security during a nuclear winter. 32 Human extinction is most likely when all three defenses are weak, that is, by risks we are unlikely to prevent, unlikely to successfully respond to, and unlikely to be resilient against . 31 The unprecedented nature of existential risks poses a special challenge in designing risk mitigation measures since humanity will not be able to learn from a track record of previous events. 14 Funding Some researchers argue that both research and other initiatives relating to existential risk are underfunded. Nick Bostrom states that more research has been done on Star Trek , snowboarding , or dung beetles than on existential risks. Bostrom's comparisons have been criticized as high-handed . 33 34 As of 2020, the Biological Weapons Convention organization had an annual budget of US$1.4 million. 35 Survival planning Some scholars propose the establishment on Earth of one or more self-sufficient, remote, permanently occupied settlements specifically created for the purpose of surviving a global disaster. 36 37 38 Economist Robin Hanson argues that a refuge permanently housing as few as 100 people would significantly improve the chances of human survival during a range of global catastrophes. 36 39 Food storage has been proposed globally, but the monetary cost would be high. Furthermore, it would likely contribute to the current millions of deaths per year due to malnutrition . 40 In 2022, a team led by David Denkenberger modeled the cost-effectiveness of resilient foods to artificial general intelligence (AGI) safety and found ~98-99% confidence for a higher et al. (March 5, 2010). The Chicxulub Asteroid Impact and Mass Extinction at the Cretaceous-Paleogene Boundary (PDF) . Science . 327 (5970): 1214– 1218. Bibcode : 2010Sci...327.1214S . doi : 10.1126/science.1177265 . PMID 20203042 . ↑ Bostrom, Nick (2008). Global Catastrophic Risks (PDF) . Oxford University Press. p. 1. Bibcode : 2008gcr..book.....B . ↑ Ripple WJ, Wolf C, Newsome TM, Galetti M, Alamgir M, Crist E, Mahmoud MI, Laurance WF (November 13, 2017). World Scientists' Warning to Humanity: A Second Notice . BioScience . 67 (12): 1026– 1028. doi : 10.1093/biosci/bix125 . hdl : 11336/71342 . ↑ Bostrom, Nick (March 2002). Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards . Journal of Evolution and Technology . 9 . 1 2 3 4 5 6 Bostrom, Nick (2013). Existential Risk Prevention as Global Priority . Global Policy . 4 (1): 15– 3. doi : 10.1111/1758-5899.12002 . ↑ Bostrom, Nick; Cirkovic, Milan (2008). Global Catastrophic Risks . Oxford: Oxford University Press. p. 1. ISBN 978-0-19-857050-9 . ↑ Ziegler, Philip (2012). The Black Death . Faber and Faber. p. 397. ISBN 9780571287116 . ↑ Muehlhauser, Luke (March 15, 2017). How big a deal was the Industrial Revolution? . lukemuelhauser.com . Retrieved August 3, 2020 . ↑ Taubenberger, Jeffery; Morens, David (2006). 1918 Influenza: the Mother of All Pandemics . Emerging Infectious Diseases . 12 (1): 15– 22. doi : 10.3201/eid1201.050979 . PMC 3291398 . PMID 16494711 . ↑ Posner, Richard A. (2006). Catastrophe: Risk and Response . Oxford: Oxford University Press. ISBN 978-0195306477 . Introduction, What is Catastrophe? ↑ Ord, Toby (2020). The Precipice: Existential Risk and the Future of Humanity . New York: Hachette. ISBN 9780316484916 . This is an equivalent, though crisper statement of Nick Bostrom 's definition: An existential risk is one that threatens the premature extinction of Earth-originating intelligent life or the permanent and drastic destruction of its potential for desirable future development. Source: Bostrom, Nick (2013). Existential Risk Prevention as Global Priority . Global Policy. 4:15-31. ↑ Cotton-Barratt, Owen; Ord, Toby (2015), Existential risk and existential hope: Definitions (PDF) , Future of Humanity Institute – Technical Report #2015-1, pp. 1– 4 ↑ Bostrom, Nick (2009). Astronomical Waste: The opportunity cost of delayed technological development . Utilitas . 15 (3): 308– 314. doi : 10.1017/s0953820800004076 . 1 2 3 4 5 6 7 8 Ord, Toby (2020). The Precipice: Existential Risk and the Future of Humanity . New York: Hachette. ISBN 9780316484916 . 1 2 Bryan Caplan (2008). The totalitarian threat . Global Catastrophic Risks , eds. Bostrom Cirkovic (Oxford University Press): 504–519. ISBN 9780198570509 ↑ Glover, Dennis (June 1, 2017). Did George Orwell secretly rewrite the end of Nineteen Eighty-Four as he lay dying? . The Sydney Morning Herald . Retrieved November 21, 2021 . Winston's creator, George Orwell, believed that freedom would eventually defeat the truth-twisting totalitarianism portrayed in Nineteen Eighty-Four. ↑ Orwell, George (1949). Nineteen Eighty-Four. A novel . London: Secker Warburg. page needed ↑ Baum, Seth D. (2023). Assessing natural global catastrophic risks . Natural Hazards . 115 (3): 2699– 2719. Bibcode : 2023NatHa.115.2699B . doi : 10.1007/s11069-022-05660-w . PMC 9553633 . PMID 36245947 . ↑ Scouras, James (2019). Nuclear War as a Global Catastrophic Risk . Journal of Benefit-Cost Analysis . 10 (2): 274– 295. doi : 10.1017/bca.2019.16 . ↑ Sagan, Carl (Winter 1983). Nuclear War and Climatic Catastrophe: Some Policy Implications . Foreign Affairs . Council on Foreign Relations. doi : 10.2307/20041818 . JSTOR 20041818 . Retrieved August 4, 2020 . ↑ Jebari, Karim (2014). Existential Risks: Exploring a Robust Risk Reduction Strategy . Science and Engineering Ethics . 21 (3): 541– 54. doi : 10.1007/s11948-014-9559-3 . PMID 24891130 . 1 2 Cirkovic, Milan M. ; Bostrom, Nick ; Sandberg, Anders (2010). Anthropic Shadow: Observation Selection Effects and Human Extinction Risks . Risk Analysis . 30 (10): 1495– 1506. Bibcode : 2010RiskA..30.1495C . doi : 10.1111/j.1539-6924.2010.01460.x . PMID 20626690 . ↑ Kemp, Luke (February 2019). Are we on the road to civilization collapse? . BBC . Retrieved August 12, 2021 . ↑ Ord, Toby (2020). The Precipice: Existential Risk and the Future of Humanity . Hachette Books. ISBN 9780316484893 . Europe survived losing 25 to 50 percent of its population in the Black Death, while keeping civilization firmly intact 1 2 Yudkowsky, Eliezer (2008). Cognitive Biases Potentially Affecting Judgment of Global Risks . Global Catastrophic Risks : 91– 119. Bibcode : 2008gcr..book...86Y . ↑ Desvousges, William H.; Johnson, F. Reed; Dunford, Richard W.; Hudson, Sara P.; Wilson, K. Nicole; Boyle, Kevin J. (1993). Measuring Natural Resource Damages with Contingent Valuation: Tests of Validity and Reliability . Contingent Valuation - A Critical Assessment . Contributions to Economic Analysis. Vol. 220. pp. 91– 164. doi : 10.1016/B978-0-444-81469-2.50009-2 . ISBN 978-0-444-81469-2 . ↑ Bostrom 2013 . ↑ Yudkowsky, Eliezer (2008). Cognitive biases potentially affecting judgement of global risks . Global Catastrophic Risks . doi : 10.1093/oso/9780198570509.003.0009 . ISBN 978-0-19-857050-9 . ↑ We're Underestimating the Risk of Human Extinction . The Atlantic. March 6, 2012 . Retrieved July 1, 2016 . ↑ Wilson, Edward O. (May 30, 1993). IS HUMANITY SUICIDAL? . The New York Times . Also published as: Wilson, Edward O. (January 1993). Is humanity suicidal? . Biosystems . 31 ( 2– 3): 235– 242. Bibcode : 1993BiSys..31..235W . doi : 10.1016/0303-2647(93)90052-E . PMID 8155855 . 1 2 Cotton-Barratt, Owen; Daniel, Max; Sandberg, Anders (2020). Defence in Depth Against Human Extinction: Prevention, Response, Resilience, and Why They All Matter . Global Policy . 11 (3): 271– 282. doi : 10.1111/1758-5899.12786 . PMC 7228299 . PMID 32427180 . ↑ García Martínez, Juan B.; Behr, Jeffray; Pearce, Joshua; Denkenberger, David (2025). Resilient foods for preventing global famine: a review of food supply interventions for global catastrophic food shocks including nuclear winter and infrastructure collapse . Critical Reviews in Food Science and Nutrition . 0 : 1– 27. doi : 10.1080/10408398.2024.2431207 . PMID 39932463 . ↑ Could science destroy the world? These scholars want to save us from a modern-day Frankenstein . Science . March 28, 2021. doi : 10.1126/science.aas9440 . ↑ Oxford Institute Forecasts The Possible Doom Of Humanity . Popular Science . 2013 . Retrieved April 20, 2020 . ↑ Toby Ord (2020). The precipice: Existential risk and the future of humanity . Hachette Books. ISBN 9780316484893 . The international body responsible for the continued prohibition of bioweapons (the Biological Weapons Convention) has an annual budget of $1.4 million - less than the average McDonald's restaurant 1 2 Matheny, Jason Gaverick (2007). Reducing the Risk of Human Extinction . Risk Analysis . 27 (5): 1335– 1344. Bibcode : 2007RiskA..27.1335M . doi : 10.1111/j.1539-6924.2007.00960.x . PMID 18076500 . ↑ Wells, Willard. (2009). Apocalypse when? . Praxis. ISBN 978-0387098364 . ↑ Wells, Willard. (2017). Prospects for Human Survival . Lifeboat Foundation. ISBN 978-0998413105 . ↑ Hanson, Robin (2008). Catastrophe, social collapse, and human extinction . Global Catastrophic Risks . doi : 10.1093/oso/9780198570509.003.0023 . ISBN 978-0-19-857050-9 . ↑ Smil, Vaclav (2003). The Earth's Biosphere: Evolution, Dynamics, and Change . MIT Press . p. 25. ISBN 978-0-262-69298-4 . ↑ Denkenberger, David C.; Sandberg, Anders; Tieman, Ross John; Pearce, Joshua M. (2022). Long term cost-effectiveness of resilient foods for global catastrophes compared to artificial general intelligence safety . International Journal of Disaster Risk Reduction . 73 102798. Bibcode : 2022IJDRR..7302798D . doi : 10.1016/j.ijdrr.2022.102798 . ↑ Lewis Smith (February 27, 2008). Doomsday vault for world's seeds is opened under Arctic mountain . The Times Online . London. Archived from the original on May 12, 2008. ↑ Suzanne Goldenberg (May 20, 2015). The doomsday vault: the seeds that could save a post-apocalyptic world . The Guardian . Retrieved June 30, 2017 . ↑ Here's how the world could end—and what we can do about it . Science . July 24, 2021. doi : 10.1126/science.aag0664 . ↑ Denkenberger, David C.; Pearce, Joshua M. (September 2015). Feeding everyone: Solving the food crisis in event of global catastrophes that kill crops or obscure the sun (PDF) . Futures . 72 : 57– 68. doi : 10.1016/j.futures.2014.11.008 . ↑ Global Challenges Foundation | Understanding Global Systemic Risk . globalchallenges.org . Archived from the original on August 16, 2017 . Retrieved August 15, 2017 . ↑ Global Catastrophic Risk Policy . gcrpolicy.com . Archived from the original on August 11, 2019 . Retrieved August 11, 2019 . ↑ Club of Rome (2018). The Climate Emergency Plan . Retrieved August 17, 2020 . ↑ Club of Rome (2019). The Planetary Emergency Plan . Retrieved August 17, 2020 . ↑ Kieft, J.; Bendell, J (2021). The responsibility of communicating difficult truths about climate influenced societal disruption and collapse: an introduction to psychological research . Institute for Leadership and Sustainability (IFLAS) Occasional Papers . 7 : 1– 39. ↑ Mankind must abandon earth or face extinction: Hawking , physorg.com , August 9, 2010 , retrieved January 23, 2012 ↑ Malik, Tariq (April 13, 2013). Stephen Hawking: Humanity Must Colonize Space to Survive . Space.com . Retrieved July 1, 2016 . ↑ Shukman, David (January 19, 2016). Hawking: Humans at risk of lethal 'own goal' . BBC News . Retrieved July 1, 2016 . ↑ Fred Hapgood (November 1986). Nanotechnology: Molecular Machines that Mimic Life (PDF) . Omni . Archived from the original (PDF) on July 27, 2013 . Retrieved June 5, 2015 . ↑ Giles, Jim (2004). Nanotech takes small step towards burying 'grey goo' . Nature . 429 (6992): 591. Bibcode : 2004Natur.429..591G . doi : 10.1038/429591b . PMID 15190320 . ↑ Sophie McBain (September 25, 2014). Apocalypse soon: the scientists preparing for the end times . New Statesman . Retrieved June 5, 2015 . ↑ Reducing Long-Term Catastrophic Risks from Artificial Intelligence . Machine Intelligence Research Institute . Retrieved June 5, 2015 . The Machine Intelligence Research Institute aims to reduce the risk of a catastrophe, should such an event eventually occur. ↑ Angela Chen (September 11, 2014). Is Artificial Intelligence a Threat? . The Chronicle of Higher Education . Retrieved June 5, 2015 . ↑ Nuclear Threat Initiative . Nuclear Threat Initiative . Retrieved June 5, 2015 . ↑ Alexander Sehmar (May 31, 2015). Isis could obtain nuclear weapon from Pakistan, warns India . The Independent . Archived from the original on June 2, 2015 . Retrieved June 5, 2015 . ↑ About the Lifeboat Foundation . The Lifeboat Foundation . Retrieved April 26, 2013 . ↑ Ashlee, Vance (July 20, 2010). The Lifeboat Foundation: Battling Asteroids, Nanobots and A.I. New York Times . Retrieved June 5, 2015 . ↑ Global Catastrophic Risk Institute . gcrinstitute.org . Retrieved March 22, 2022 . ↑ Meyer, Robinson (April 29, 2016). Human Extinction Isn't That Unlikely . The Atlantic . Boston, Massachusetts: Emerson Collective . Retrieved April 30, 2016 . ↑ Global Challenges Foundation website . globalchallenges.org . Retrieved April 30, 2016 . ↑ The Future of Life Institute . Future of Life Institute . Retrieved May 5, 2014 . ↑ Nick Bilton (May 28, 2015). Ava of 'Ex Machina' Is Just Sci-Fi (for Now) . New York Times . Retrieved June 5, 2015 . 1 2 About FHI . Future of Humanity Institute . Retrieved August 12, 2021 . ↑ About us . Centre for the Study of Existential Risk . Retrieved August 12, 2021 . ↑ Hui, Sylvia (November 25, 2012). Cambridge to study technology's risks to humans . Associated Press. Archived from the original on December 1, 2012 . Retrieved January 30, 2012 . ↑ Scott Barrett (2014). Environment and Development Economics: Essays in Honour of Sir Partha Dasgupta . Oxford University Press. p. 112. ISBN 9780199677856 . Retrieved June 5, 2015 . ↑ Millennium Alliance for Humanity The Biosphere . Millennium Alliance for Humanity The Biosphere . Retrieved June 5, 2015 . ↑ Guruprasad Madhavan (2012). Practicing Sustainability . Springer Science Business Media. p. 43. ISBN 9781461443483 . Retrieved June 5, 2015 . ↑ Center for International Security and Cooperation . Center for International Security and Cooperation . Retrieved June 5, 2015 . 1 2 Anderson, Nick (February 28, 2019). Georgetown launches think tank on security and emerging te",
  "cached_at": "2025-10-25T20:04:32.573784"
}