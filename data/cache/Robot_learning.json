{
  "title": "Robot learning",
  "summary": "Robot learning is a research field at the intersection of machine learning and robotics. It studies techniques allowing a robot to acquire novel skills or adapt to its environment through learning algorithms. The embodiment of the robot, situated in a physical embedding, provides at the same time specific difficulties and opportunities for guiding the learning process.",
  "content": "Robot learning Machine learning for robots Robot learning is a research field at the intersection of machine learning and robotics . It studies techniques allowing a robot to acquire novel skills or adapt to its environment through learning algorithms. The embodiment of the robot, situated in a physical embedding, provides at the same time specific difficulties (e.g. high-dimensionality, real time constraints for collecting data and learning) and opportunities for guiding the learning process (e.g. sensorimotor synergies, motor primitives). Example of skills that are targeted by learning algorithms include sensorimotor skills such as locomotion, grasping, active object categorization , as well as interactive skills such as joint manipulation of an object with a human peer, and linguistic skills such as the grounded and situated meaning of human language . Learning can happen either through autonomous self-exploration or through guidance from a human teacher, like for example in robot learning by imitation. Robot learning can be closely related to adaptive control , reinforcement learning as well as developmental robotics which considers the problem of autonomous lifelong acquisition of repertoires of skills. While machine learning is frequently used by computer vision algorithms employed in the context of robotics, these applications are usually not referred to as \"robot learning\". Imitation learning .mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}} Main article: Imitation learning Many research groups are developing techniques where robots learn by imitating. This includes various techniques for learning from demonstration (sometimes also referred to as \" programming by demonstration \") and observational learning . Sharing learned skills and knowledge Further information: Cloud robotics In Tellex's \"Million Object Challenge\", the goal is robots that learn how to spot and handle simple items and upload their data to the cloud to allow other robots to analyze and use the information. [ 1 ] RoboBrain is a knowledge engine for robots which can be freely accessed by any device wishing to carry out a task. The database gathers new information about tasks as robots perform them, by searching the Internet, interpreting natural language text, images, and videos, object recognition as well as interaction. The project is led by Ashutosh Saxena at Stanford University . [ 2 ] [ 3 ] RoboEarth is a project that has been described as a \" World Wide Web for robots\" − it is a network and database repository where robots can share information and learn from each other and a cloud for outsourcing heavy computation tasks. The project brings together researchers from five major universities in Germany, the Netherlands and Spain and is backed by the European Union . [ 4 ] [ 5 ] [ 6 ] [ 7 ] [ 8 ] Google Research, DeepMind , and Google X have decided to allow their robots share their experiences. [ 9 ] [ 10 ] [ 11 ] Vision-language-action model Research groups and companies are developing vision-language-action models , foundation models that allow robotic control through the combination of vision and language. Google DeepMind , Figure AI and Hugging Face are actively working on that. See also Cognitive robotics Developmental robotics Evolutionary robotics – Embodied approach to artificial intelligence Philosophical ethology#History – Field of multidisciplinary research References .mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman} ↑ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}} Schaffer, Amanda (2016-02-23). \"10 Breakthrough Technologies 2016 | Robots That Teach Each Other\" . MIT Technology Review . Retrieved 4 January 2017 . ↑ \"RoboBrain: The World's First Knowledge Engine For Robots\" . MIT Technology Review . Retrieved 4 January 2017 . ↑ Hernandez, Daniela (2014-08-25). \"The Plan to Build a Massive Online Brain for All the World's Robots\" . WIRED . Retrieved 4 January 2017 . ↑ \"Europe launches RoboEarth: 'Wikipedia for robots' \" . USA TODAY. 2014-01-17 . Retrieved 4 January 2017 . ↑ \"European researchers have created a hive mind for robots and it's being demoed this week\" . Engadget. 14 January 2014 . Retrieved 4 January 2017 . ↑ \"Robots test their own world wide web, dubbed RoboEarth\" . BBC News. 14 January 2014 . Retrieved 4 January 2017 . ↑ \" 'Wikipedia for robots': Because bots need an Internet too\" . CNET . Retrieved 4 January 2017 . ↑ \"New Worldwide Network Lets Robots Ask Each Other Questions When They Get Confused\" . Popular Science. 9 March 2013 . Retrieved 4 January 2017 . ↑ \"Google Tasks Robots with Learning Skills from One Another via Cloud Robotics\" . allaboutcircuits.com . 2017-01-02 . Retrieved 4 January 2017 . ↑ Tung, Liam (2016-10-04). \"Google's next big step for AI: Getting robots to teach each other new skills\" . ZDNet . Retrieved 4 January 2017 . ↑ \"How Robots Can Acquire New Skills from Their Shared Experience\" . Google Research Blog. 2016-10-04 . Retrieved 4 January 2017 . External links IEEE RAS Technical Committee on Robot Learning (official IEEE website) IEEE RAS Technical Committee on Robot Learning (TC members website) Robot Learning at the Max Planck Institute for Intelligent Systems and the Technical University Darmstadt Robot Learning at the Computational Learning and Motor Control lab Humanoid Robot Learning at the Advanced Telecommunication Research Center (ATR) (in English and Japanese) Learning Algorithms and Systems Laboratory at EPFL (LASA) Robot Learning at the Cognitive Robotics Lab of Juergen Schmidhuber at IDSIA and Technical University of Munich The Humanoid Project : Peter Nordin , Chalmers University of Technology Inria and Ensta ParisTech FLOWERS team, France : Autonomous lifelong learning in developmental robotics CITEC at University of Bielefeld, Germany Asada Laboratory , Department of Adaptive Machine Systems, Graduate School of Engineering, Osaka University, Japan The Laboratory for Perceptual Robotics , University of Massachusetts Amherst Amherst, USA Centre for Robotics and Neural Systems , Plymouth University Plymouth, United Kingdom Robot Learning Lab at Carnegie Mellon University Project Learning Humanoid Robots at University of Bonn Skilligent Robot Learning and Behavior Coordination System (commercial product) Robot Learning class at Cornell University Robot Learning and Interaction Lab at Italian Institute of Technology Reinforcement learning for robotics Archived 2018-10-08 at the Wayback Machine at Delft University of Technology .mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" · \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"} .mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}} .mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}} v t e Robotics Main articles Outline Glossary Index History Geography Hall of Fame Ethics Laws Competitions AI competitions Types Aerobot Anthropomorphic Humanoid Android Cyborg Gynoid Claytronics Companion Automaton Animatronic Audio-Animatronics Industrial Articulated arm Domestic Educational Entertainment Juggling Military Medical Service Disability Agricultural Food service Retail BEAM robotics Soft robotics Classifications Biorobotics Cloud robotics Continuum robot Unmanned vehicle aerial ground Mobile robot Microbotics Nanorobotics Necrobotics Robotic spacecraft Space probe Swarm Telerobotics Underwater remotely-operated Robotic fish Locomotion Tracks Walking Hexapod Climbing Electric unicycle Robotic fins Navigation and mapping Motion planning Simultaneous localization and mapping Visual odometry Vision-guided robot systems Research Evolutionary Kits Simulator Suite Open-source Software Adaptable Developmental Human–robot interaction Paradigms Perceptual Situated Ubiquitous Companies ABB Amazon Robotics Anybots Barrett Technology Boston Dynamics Doosan Robotics Energid Technologies FarmWise FANUC Figure AI Foster-Miller Harvest Automation HD Hyundai Robotics Honeybee Robotics Intuitive Surgical IRobot KUKA Rainbow Robotics Starship Technologies Symbotic Universal Robotics Wolf Robotics Yaskawa Related Critique of work Powered exoskeleton Workplace robotics safety Robotic tech vest Technological unemployment Terrainability Fictional robots Category Outline",
  "cached_at": "2025-10-25T19:34:40.234560"
}