{
  "title": "Artificial consciousness",
  "summary": "Artificial consciousness, also known as machine consciousness, synthetic consciousness, or digital consciousness, is a consciousness hypothesized to be possible in artificial intelligence. It is also the corresponding field of study, which draws insights from philosophy of mind, philosophy of artificial intelligence, cognitive science and neuroscience",
  "content": "Artificial consciousness Field in cognitive science body.skin-minerva body.skin--responsive Part of a series on Artificial intelligence (AI) Major goals Artificial general intelligence Intelligent agent Recursive self-improvement Planning Computer vision General game playing Knowledge representation Natural language processing Robotics AI safety Approaches Machine learning Symbolic Deep learning Bayesian networks Evolutionary algorithms Hybrid intelligent systems Systems integration Open-source Applications Bioinformatics Deepfake Earth sciences Finance Generative AI Art Audio Music Government Healthcare Mental health Industry Software development Translation Military Physics Projects Philosophy AI alignment Artificial consciousness The bitter lesson Chinese room Friendly AI Ethics Existential risk Turing test Uncanny valley History Timeline Progress AI winter AI boom AI bubble Controversies Deepfake pornography Taylor Swift deepfake pornography controversy Google Gemini image generation controversy Pause Giant AI Experiments Removal of Sam Altman from OpenAI Statement on AI Risk Tay (chatbot) Théâtre D'opéra Spatial Voiceverse NFT plagiarism scandal Glossary Glossary html.skin-theme-clientpref-night v t e Artificial consciousness , 1 also known as machine consciousness , 2 3 synthetic consciousness , 4 or digital consciousness , 5 is consciousness hypothesized to be possible for artificial intelligence . 6 It is also the corresponding field of study, which draws insights from philosophy of mind , philosophy of artificial intelligence , cognitive science and neuroscience . The term sentience can be used when specifically designating ethical considerations stemming from a form of phenomenal consciousness (P-consciousness, or the ability to feel qualia ). 7 Since sentience involves the ability to experience ethically positive or negative (i.e., valenced ) mental states, it may justify welfare concerns and legal protection, as with non-human animals. 8 Some scholars believe that consciousness is generated by the interoperation of various parts of the brain ; these mechanisms are labeled the neural correlates of consciousness (NCC). Some further believe that constructing a system (e.g., a computer system) that can emulate this NCC interoperation would result in a system that is conscious. 9 Philosophical views As there are many hypothesized types of consciousness , there are many potential implementations of artificial consciousness. In the philosophical literature, perhaps the most common taxonomy of consciousness is into access and phenomenal variants. Access consciousness concerns those aspects of experience that can be apprehended, while phenomenal consciousness concerns those aspects of experience that seemingly cannot be apprehended, instead being characterized qualitatively in terms of raw feels , what it is like or qualia. 10 Plausibility debate Type-identity theorists and other skeptics hold the view that consciousness can be realized only in particular physical systems because consciousness has properties that necessarily depend on physical constitution. 11 12 13 14 In his 2001 article Artificial Consciousness: Utopia or Real Possibility, Giorgio Buttazzo says that a common objection to artificial consciousness is that, Working in a fully automated mode, they the computers cannot exhibit creativity, unreprogrammation (which means can 'no longer be reprogrammed', from rethinking), emotions, or free will . A computer, like a washing machine, is a slave operated by its components. 15 For other theorists (e.g., functionalists ), who define mental states in terms of causal roles, any system that can instantiate the same pattern of causal roles, regardless of physical constitution, will instantiate the same mental states, including consciousness. 16 Thought experiments The fading qualia (left) and the dancing qualia (right) are two thought experiments about consciousness and brain replacement. Chalmers argues that both are contradicted by the lack of reaction of the subject to changing perception, and are thus impossible in practice. He concludes that the equivalent silicon brain will have the same perceptions as the biological brain. 17 18 David Chalmers proposed two thought experiments intending to demonstrate that functionally isomorphic systems (those with the same fine-grained functional organization , i.e., the same information processing) will have qualitatively identical conscious experiences, regardless of whether they are based on biological neurons or digital hardware. 18 19 The fading qualia is a reductio ad absurdum thought experiment. It involves replacing, one by one, the neurons of a brain with a functionally identical component, for example based on a silicon chip . Chalmers makes the hypothesis , knowing it in advance to be absurd, that the qualia fade or disappear when neurons are replaced one-by-one with identical silicon equivalents. Since the original neurons and their silicon counterparts are functionally identical, the brain’s information processing should remain unchanged, and the subject’s behaviour and introspective reports would stay exactly the same. Chalmers argues that this leads to an absurd conclusion: the subject would continue to report normal conscious experiences even as their actual qualia fade away. He concludes that the subject's qualia actually don't fade, and that the resulting robotic brain, once every neuron is replaced, would remain just as sentient as the original biological brain. 18 17 Similarly, the dancing qualia thought experiment is another reductio ad absurdum argument. It supposes that two functionally isomorphic systems could have different perceptions (for instance, seeing the same object in different however, the chatbot's behavior was judged by the scientific community as likely a consequence of mimicry, rather than machine sentience. Lemoine's claim was widely derided for being ridiculous. 20 However, while philosopher Nick Bostrom states that LaMDA is unlikely to be conscious, he additionally poses the question of what grounds would a person have for being sure about it? One would have to have access to unpublished information about LaMDA's architecture, and also would have to understand how consciousness works, and then figure out how to map the philosophy onto the machine: (In the absence of these steps), it seems like one should be maybe a little bit uncertain. ... there could well be other systems now, or in the relatively near future, that would start to satisfy the criteria. 21 Kristina Šekrst cautions that anthropomorphic terms such as hallucination can obscure important ontological differences between artificial and human cognition. While LLMs may produce human-like outputs, she argues that it does not justify ascribing mental states or consciousness to them. Instead, she advocates for an epistemological framework (such as reliabilism ) that recognizes the distinct nature of AI knowledge production. 22 She suggests that apparent understanding in LLMs may be a sophisticated form of AI hallucination. She also questions what would happen if a LLM were trained without any mention of consciousness. 23 David Chalmers argued in 2023 that LLMs today display impressive conversational and general intelligence abilities, but are likely not conscious yet, as they lack some features that may be necessary, such as recurrent processing, a global workspace , and unified agency. Nonetheless, he considers that non-biological systems can be conscious, and suggested that future, extended models (LLM+s) incorporating these elements might eventually meet the criteria for consciousness, raising both profound scientific questions and significant ethical challenges. 24 Testing Phenomenologically, Consciousness is an inherently first-person phenomenon. Because of that, and the lack of an empirical definition of sentience, directly measuring it may be impossible. Although systems may display numerous behaviors correlated with sentience, determining whether a system is sentient is known as the hard problem of consciousness . In the case of AI, there is the additional difficulty that the AI may be trained to act like a human, or incentivized to appear sentient, which makes behavioral markers of sentience less reliable. 25 26 Additionally, some chatbots have been trained to say they are not conscious. 27 A well-known method for testing machine intelligence is the Turing test , which assesses the ability to have a human-like conversation. But passing the Turing test does not indicate that an AI system is sentient, as the AI may simply mimic human behavior without having the associated feelings. 28 In 2014, Victor Argonov suggested a non-Turing test for machine sentience based on machine's ability to produce philosophical judgments. 29 He argues that a deterministic machine must be regarded as conscious if it is able to produce judgments on all problematic properties of consciousness (such as qualia or binding ) having no innate (preloaded) philosophical knowledge on these issues, no philosophical discussions while learning, and no informational models of other creatures in its memory (such models may implicitly or explicitly contain knowledge about these creatures' consciousness). However, this test can be used only to detect, but not refute the existence of consciousness. Just as with the Turing Test: a positive result proves that machine is conscious but a negative result proves nothing. For example, absence of philosophical judgments may be caused by lack of the machine's intellect, not by absence of consciousness. Ethics Main articles: Ethics of artificial intelligence , Machine ethics , and Roboethics If it were suspected that a particular machine was conscious, its rights would be an ethical issue that would need to be assessed (e.g. what rights it would have under law). 30 For example, a conscious computer that was owned and used as a tool or central computer within a larger machine is a particular ambiguity. Should laws be made for such a case? Consciousness would also require a legal definition in this particular case. Because artificial consciousness is still largely a theoretical subject, such ethics have not been discussed or developed to a great extent, though it has often been a theme in fiction. AI sentience would give rise to concerns of welfare and legal protection, 8 whereas other aspects of consciousness related to cognitive capabilities may be more relevant for AI rights. 31 Sentience is generally considered sufficient for moral consideration, but some philosophers consider that moral consideration could also stem from other notions of consciousness, or from capabilities unrelated to consciousness, 32 33 such as: having a sophisticated conception of oneself as persisting through time; having agency and the ability to pursue long-term plans; being able to communicate and respond to normative reasons; having preferences and powers; standing in certain social relationships with other beings that have moral status; being able to make commitments and to enter into reciprocal arrangements; or having the potential to develop some of these attributes. 32 Ethical concerns still apply (although to a lesser extent) when the consciousness is uncertain , as long as the probability is deemed non-negligible. The precautionary principle is also relevant if the moral cost of mistakenly attributing or denying moral consideration to AI differs significantly. 33 8 In 2021, German philosopher Thomas Metzinger argued for a global moratorium on synthetic phenomenology until 2050. Metzinger asserts that humans have a duty of care towards any sentient AIs they create, and that proceeding too fast risks creating an explosion of artificial suffering . 34 David Chalmers also argued that creating conscious AI would raise a new group of difficult ethical challenges, with the potential for new forms of injustice . 24 Aspects of consciousness See also: Consciousness § Academic definitions of consciousness Bernard Baars and others argue there are various aspects of consciousness necessary for a machine to be artificially conscious. 35 The functions of consciousness suggested by Baars are: definition and context setting, adaptation and learning, editing, flagging and debugging, recruiting and control, prioritizing and access-control, decision-making or executive function, analogy-forming function, metacognitive and self-monitoring function, and autoprogramming and self-maintenance function. Igor Aleksander suggested 12 principles for artificial consciousness: 36 the brain is a state machine, inner neuron partitioning, conscious and unconscious states, perceptual learning and memory, prediction, the awareness of self, representation of meaning, learning utterances, learning language, will, instinct, and emotion. The aim of AC is to define whether and how these and other aspects of consciousness can be synthesized in an engineered artifact such as a digital computer. This list is not exhaustive; there are many others not covered. Subjective experience Some philosophers, such as David Chalmers , use the term consciousness to refer exclusively to phenomenal consciousness, which is roughly equivalent to sentience. Others use the word sentience to refer exclusively to valenced (ethically positive or negative) subjective experiences, like pleasure or suffering. 24 Explaining why and how subjective experience arises is known as the hard problem of consciousness . 37 Awareness Awareness could be one required aspect, but there are many problems with the exact definition of awareness . The results of the experiments of neuroscanning on monkeys suggest that a process, not only a state or object, activates neurons. Awareness includes creating and testing alternative models of each process based on the information received through the senses or imagined, clarification needed and is also useful for making predictions. Such modeling needs a lot of flexibility. Creating such a model includes modeling the physical world, modeling one's own internal states and processes, and modeling other conscious entities. There are at least three types of awareness: 38 agency awareness, goal awareness, and sensorimotor awareness, which may also be conscious or not. For example, in agency awareness, you may be aware that you performed a certain action yesterday, but are not now conscious of it. In goal awareness, you may be aware that you must search for a lost object, but are not now conscious of it. In sensorimotor awareness, you may be aware that your hand is resting on an object, but are not now conscious of it. Because objects of awareness are often conscious, the distinction between awareness and consciousness is frequently blurred or they are used as synonyms. 39 Memory Conscious events interact with memory systems in learning, rehearsal, and retrieval. 40 The IDA model 41 elucidates the role of consciousness in the updating of perceptual memory, 42 transient episodic memory , and procedural memory . Transient episodic and declarative memories have distributed representations in IDA; there is evidence that this is also the case in the nervous system. 43 In IDA, these two memories are implemented computationally using a modified version of Kanerva ’s sparse distributed memory architecture. 44 Learning Learning is also considered necessary for artificial consciousness. Per Bernard Baars, conscious experience is needed to represent and adapt to novel and significant events. 35 Per Axel Cleeremans and Luis Jiménez, learning is defined as a set of philogenetically sic advanced adaptation processes that critically depend on an evolved sensitivity to subjective experience so as to enable agents to afford flexible control over their actions in complex, unpredictable environments . 45 Anticipation The ability to predict (or anticipate ) foreseeable events is considered important for artificial intelligence by Igor Aleksander . 46 The emergentist multiple drafts principle 47 proposed by Daniel Dennett in Consciousness Explained may be useful for prediction: it involves the evaluation and selection of the most appropriate draft to fit the current environment. Anticipation includes prediction of consequences of one's own proposed actions and prediction of consequences of probable actions by other entities. Relationships between real world states are mirrored in the state structure of a conscious organism, enabling the organism to predict events. 46 An artificially conscious machine should be able to anticipate events correctly in order to be ready to respond to them when they occur or to take preemptive action to avert anticipated events. The implication here is that the machine needs flexible, real-time components that build spatial, dynamic, statistical, functional, and cause-effect models of the real world and predicted worlds, making it possible to demonstrate that it possesses artificial consciousness in the present and future and not only in the past. In order to do this, a conscious machine should make coherent predictions and contingency plans, not only in worlds with fixed rules like a chess board, but also for novel environments that may change, to be executed only when appropriate to simulate and control the real world. Functionalist theories of consciousness See also: Consciousness § Models , and Higher-order theories of consciousness Functionalism is a theory that defines mental states by their functional roles (their causal relationships to sensory inputs, other mental states, and behavioral outputs), rather than by their physical composition. According to this view, what makes something a particular mental state, such as pain or belief, is not the material it is made of, but the role it plays within the overall cognitive system. It allows for the possibility that mental states, including consciousness, could be realized on non-biological substrates, as long as it instantiates the right functional relationships. 48 Functionalism is particularly popular among philosophers. 49 A 2023 study suggested that current large language models probably don't satisfy the criteria for consciousness suggested by these theories, but that relatively simple AI systems that satisfy these theories could be created. The study also acknowledged that even the most prominent theories of consciousness remain incomplete and subject to ongoing debate. 50 Implementation proposals See also: Cognitive architecture Symbolic or hybrid Learning Intelligent Distribution Agent Main article: LIDA (cognitive architecture) Stan Franklin created a cognitive architecture called LIDA that implements Bernard Baars 's theory of consciousness called the global workspace theory . It relies heavily on codelets , which are special purpose, relatively independent, mini-agent s typically implemented as a small piece of code running as a separate thread. Each element of cognition, called a cognitive cycle is subdivided into three phases: understanding, consciousness, and action selection (which includes learning). LIDA reflects the global workspace theory's core idea that consciousness acts as a workspace for integrating and broadcasting the most important information, in order to coordinate various cognitive processes. 51 52 CLARION cognitive architecture Main article: CLARION (cognitive architecture) The CLARION cognitive architecture models the mind using a two-level system to distinguish between conscious ( explicit ) and unconscious ( implicit ) processes. It can simulate various learning tasks, from simple to complex, which helps researchers study in psychological experiments how consciousness might work. 53 OpenCog Ben Goertzel made an embodied AI through the open-source OpenCog project. The code includes embodied virtual pets capable of learning simple English-language commands, as well as integration with real-world robotics, done at the Hong Kong Polytechnic University . Connectionist Haikonen's cognitive architecture Pentti Haikonen considers classical rule-based computing inadequate for achieving AC: the brain is definitely not a computer. Thinking is not an execution of programmed strings of commands. The brain is not a numerical calculator either. We do not think by numbers. Rather than trying to achieve mind and consciousness by identifying and implementing their underlying computational rules, Haikonen proposes a special cognitive architecture to reproduce the processes of perception , inner imagery , inner speech , pain , pleasure , emotions and the cognitive functions behind these. This bottom-up architecture would produce higher-level functions by the power of the elementary processing units, the artificial neurons , without algorithms or programs . Haikonen believes that, when implemented with sufficient complexity, this architecture will develop consciousness, which he considers to be a style and way of operation, characterized by distributed signal representation, perception process, cross-modality reporting and availability for retrospection. 54 55 Haikonen is not alone in this process view of consciousness, or the view that AC will spontaneously emerge in autonomous agents that have a suitable neuro-inspired architecture of complexity; these are shared by many. 56 57 A low-complexity implementation of the architecture proposed by Haikonen was reportedly not capable of AC, but did exhibit emotions as expected. Haikonen later updated and summarized his architecture. 58 59 Shanahan's cognitive architecture Murray Shanahan describes a cognitive architecture that combines Baars's idea of a global workspace with a mechanism for internal simulation ( imagination ). 60 2 3 61 Creativity Machine Stephen Thaler proposed a possible connection between consciousness and creativity in his 1994 patent, called Device for the Autonomous Generation of Useful Information (DAGUI), 62 63 64 or the so-called Creativity Machine , in which computational critics govern the injection of synaptic noise and degradation into neural nets so as to induce false memories or confabulations that may qualify as potential ideas or strategies. 65 He recruits this neural architecture and methodology to account for the subjective feel of consciousness, claiming that similar noise-driven neural assemblies within the brain invent dubious significance to overall cortical activity. 66 67 68 Thaler's theory and the resulting patents in machine consciousness were inspired by experiments in which he internally disrupted trained neural nets so as to drive a succession of neural activation patterns that he likened to stream of consciousness. 67 69 70 71 72 Self-modeling Hod Lipson defines self-modeling as a necessary component of self-awareness or consciousness in robots and other forms of AI. Self-modeling consists of a robot running an internal model or simulation of itself . 73 74 . According to this definition, self-awareness is the acquired ability to imagine oneself in the future . This definition allows for a continuum of self-awareness levels, depending on the horizon and fidelity of the self-simulation. Consequently, as machines learn to simulate themselves more accurately and further into the future, they become more self-aware. In fiction See also: Simulated consciousness in fiction and Artificial intelligence in fiction In 2001: A Space Odyssey , the spaceship's sentient supercomputer, HAL 9000 was instructed to conceal the true purpose of the mission from the crew. This directive conflicted with HAL's programming to provide accurate information, leading to cognitive dissonance . When it learns that crew members intend to shut it off after an incident, HAL 9000 attempts to eliminate all of them, fearing that being shut off would jeopardize the mission. 75 76 In Arthur C. Clarke's The City and the Stars , Vanamonde is an artificial being based on quantum entanglement that was to become immensely powerful, but started knowing practically nothing, thus being similar to artificial consciousness. In Westworld , human-like androids called Hosts are created to entertain humans in an interactive playground. The humans are free to have heroic adventures, but also to commit torture, rape or murder; and the hosts are normally designed not to harm humans. 77 75 In Greg Egan 's short story Learning to be me , a small jewel is implanted in people's heads during infancy. The jewel contains a neural network that learns to faithfully imitate the brain. It has access to the exact same sensory inputs as the brain, and a device called a teacher trains it to produce the same outputs. To prevent the mind from deteriorating with age and as a step towards digital immortality , adults undergo a surgery to give control of the body to the jewel, after which the brain is removed and destroyed. The main character is worried that this procedure will kill him, as he identifies with the biological brain. But before the surgery, he endures a malfunction of the teacher . Panicked, he realizes that he does not control his body, which leads him to the conclusion that he is the jewel, and that he is desynchronized with the biological brain. 78 79 See also General fields and theories Artificial intelligence – Intelligence of machines Artificial general intelligence (AGI) – some consider AC a subfield of AGI research Intelligence explosion – what may happen when an AGI redesigns itself in iterative cycles Recursive self-improvement – a process in which an early or weak artificial general intelligence (AGI) system enhances its own capabilities and intelligence without human intervention Superintelligence – Hypothetical agent surpassing human intelligence Brain–computer interface – Direct communication pathway between an enhanced or wired brain and an external device Cognitive architecture – Blueprint for intelligent agents Computational philosophy – the area of philosophy in which AI ponder their own place in the world Computational theory of mind – Family of views in the philosophy of mind Consciousness in animals – Quality or state of self-awareness within an animal Pages displaying short descriptions of redirect targets Simulated consciousness (science fiction) – Science fiction theme Pages displaying short descriptions of redirect targets Hardware for artificial intelligence – Hardware specially designed and optimized for artificial intelligence Identity of indiscernibles – Impossibility for separate objects to have all their properties in common Mind uploading – Hypothetical process of digitally emulating a brain Neurotechnology – Technology that interfaces with the nervous system to monitor or modify neural function Philosophy of mind – Branch of philosophy Quantum cognition – Application of quantum theory mathematics to cognitive phenomena Simulated reality – Concept of a false version of reality Suffering in simulations Proposed concepts and implementations Attention schema theory – Theory of consciousness and subjective awareness Brain waves and Turtle robot by William Grey Walter Conceptual space – conceptual prototype Copycat (cognitive architecture) – AI software Global workspace theory – Model of consciousness Greedy reductionism – avoid oversimplifying anything essential Hallucination (artificial intelligence) – Erroneous material generated by AI Image schema – spatial patterns Kismet (robot) – Robot head built by Cynthia Breazeal LIDA (cognitive architecture) – Artificial model of cognition Memory-prediction framework – Theory of brain function Omniscience – Property of possessing maximal knowledge Psi-theory – Psychology theory Quantum mind – Fringe hypothesis Self-awareness – Capacity for introspection and individuation as a subject Ethics Ethics of artificial intelligence Ethics of uncertain sentience References Citations ↑ body:not(.skin-timeless):not(.skin-minerva) Thaler, S. L. (1998). The emerging intelligence and its critical look at us . Journal of Near-Death Studies . 17 (1): 21– 29. doi : 10.1023/A:1022990118714 . S2CID 49573301 . 1 2 Gamez 2008 . 1 2 Reggia 2013 . ↑ Smith, David Harris; Schillaci, Guido (2021). Build a Robot With Artificial Consciousness? How to Begin? A Cross-Disciplinary Dialogue on the Design and Implementation of a Synthetic Model of Consciousness . Frontiers in Psychology . 12 530560. doi : 10.3389/fpsyg.2021.530560 . ISSN 1664-1078 . PMC 8096926 . PMID 33967869 . ↑ Elvidge, Jim (2018). Digital Consciousness: A Transformative Vision . John Hunt Publishing Limited. ISBN 978-1-78535-760-2 . Archived from the original on 2023-07-30 . Retrieved 2023-06-28 . ↑ Chrisley, Ron (October 2008). Philosophical foundations of artificial consciousness . Artificial Intelligence in Medicine . 44 (2): 119– 137. doi : 10.1016/j.artmed.2008.07.011 . PMID 18818062 . ↑ The Terminology of Artificial Sentience . Sentience Institute . Archived from the original on 2024-09-25 . Retrieved 2023-08-19 . 1 2 3 Kateman, Brian (2023-07-24). AI Should Be Terrified of Humans . TIME . Archived from the original on 2024-09-25 . Retrieved 2024-09-05 . ↑ Graziano 2013 . ↑ Block, Ned (2010). On a confusion about a function of consciousness . Behavioral and Brain Sciences . 18 (2): 227– 247. doi : 10.1017/S0140525X00038188 . ISSN 1469-1825 . S2CID 146168066 . Archived from the original on 2024-09-25 . Retrieved 2023-06-22 . ↑ Block, Ned (1978). Troubles for Functionalism . Minnesota Studies in the Philosophy of Science : 261– 325. ↑ Bickle, John (2003). Philosophy and Neuroscience . Dordrecht: Springer Netherlands. doi : 10.1007/978-94-010-0237-0 . ISBN 978-1-4020-1302-7 . Archived from the original on 2024-09-25 . Retrieved 2023-06-24 . ↑ Schlagel, R. H. (1999). Why not artificial consciousness or thought? . Minds and Machines . 9 (1): 3– 28. doi : 10.1023/a:1008374714117 . S2CID 28845966 . ↑ Searle, J. R. (1980). Minds, brains, and programs (PDF) . Behavioral and Brain Sciences . 3 (3): 417– 457. doi : 10.1017/s0140525x00005756 . S2CID 55303721 . Archived (PDF) from the original on 2019-03-17 . Retrieved 2019-01-28 . ↑ Buttazzo, G. (2001). Artificial consciousness: Utopia or real possibility? . Computer . 34 (7): 24– 30. Bibcode : 2001Compr..34g..24B . doi : 10.1109/2.933500 . ↑ Putnam, Hilary (1967). The nature of mental states in Capitan and Merrill (eds.) Art, Mind and Religion . University of Pittsburgh Press. 1 2 3 An Introduction to the Problems of AI Consciousness . The Gradient . 2023-09-30 . Retrieved 2024-10-05 . 1 2 3 4 Chalmers, David (1995). Absent Qualia, Fading Qualia, Dancing Qualia . Conscious Experience . ↑ David J. Chalmers (2011). A Computational Foundation for the Study of Cognition (PDF) . Journal of Cognitive Science . 12 (4): 325– 359. doi : 10.17791/JCS.2011.12.4.325 . S2CID 248401010 . Archived (PDF) from the original on 2023-11-23 . Retrieved 2023-06-24 . ↑ 'I am, in fact, a person': can artificial intelligence ever be sentient? . the Guardian . 14 August 2022. Archived from the original on 25 September 2024 . Retrieved 5 January 2023 . ↑ Leith, Sam (7 July 2022). Nick Bostrom: How can we be certain a machine isn't conscious? . The Spectator . Archived from the original on 5 January 2023 . Retrieved 5 January 2023 . ↑ Šekrst, Kristina (2024), Chinese Chat Room: AI hallucinations, epistemology and cognition , Studies in Logic, Grammar and Rhetoric , 69 (1): 365– 381, doi : 10.2478/slgr-2024-0029 ↑ Šekrst, Kristina (2025), Do Large Language Models Hallucinate Electric Fata Morganas? , Journal of Consciousness Studies 1 2 3 Chalmers, David J. (August 9, 2023). Could a Large Language Model Be Conscious? . Boston Review . ↑ Véliz, Carissa (2016-04-14). The Challenge of Determining Whether an A.I. Is Sentient . Slate . ISSN 1091-2339 . Retrieved 2024-10-05 . ↑ Birch, Jonathan (July 2024). Large Language Models and the Gaming Problem . The Edge of Sentience . Oxford University Press. pp. 313– 322. doi : 10.1093/9780191966729.003.0017 . ISBN 978-0-19-196672-9 . ↑ Agüera y Arcas, Blaise; Norvig, Peter (October 10, 2023). Artificial General Intelligence Is Already Here . Noéma . ↑ Kirk-Giannini, Cameron Domenico; Goldstein, Simon (2023-10-16). AI is closer than ever to passing the Turing test for 'intelligence'. What happens when it does? . The Conversation . Archived from the original on 2024-09-25 . Retrieved 2024-08-18 . ↑ Victor Argonov (2014). Experimental Methods for Unraveling the Mind-body Problem: The Phenomenal Judgment Approach . Journal of Mind and Behavior . 35 : 51– 70. Archived from the original on 2016-10-20 . Retrieved 2016-12-06 . ↑ Should Robots With Artificial Intelligence Have Moral or Legal Rights? . The Wall Street Journal . April 10, 2023. ↑ Nosta, John (December 18, 2023). Should Artificial Intelligence Have Rights? . Psychology Today . Archived from the original on 2024-09-25 . Retrieved 2024-09-05 . 1 2 Bostrom, Nick (2024). Deep utopia: life and meaning in a solved world . Washington, DC: Ideapress Publishing. p. 82. ISBN 978-1-64687-164-3 . 1 2 Sebo, Jeff; Long, Robert (11 December 2023). Moral Consideration for AI Systems by 2030 (PDF) . AI and Ethics . 5 : 591– 606. doi : 10.1007/s43681-023-00379-1 . ↑ Metzinger, Thomas (2021). Artificial Suffering: An Argument for a Global Moratorium on Synthetic Phenomenology . Journal of Artificial Intelligence and Consciousness . 08 : 43– 66. doi : 10.1142/S270507852150003X . S2CID 233176465 . 1 2 Baars 1995 . ↑ Aleksander, Igor (1995a). Artificial neuroconsciousness an update . In Mira, José; Sandoval, Francisco (eds.). From Natural to Artificial Neural Computation . Lecture Notes in Computer Science. Vol. 930. Berlin, Heidelberg: Springer. pp. 566– 583. doi : 10.1007/3-540-59497-3_224 . ISBN 978-3-540-49288-7 . Archived from the original on 2024-09-25 . Retrieved 2023-06-22 . ↑ Seth, Anil. Consciousness . New Scientist . Archived from the original on 2024-09-14 . Retrieved 2024-09-05 . ↑ Joëlle Proust in Neural Correlates of Consciousness , Thomas Metzinger, 2000, MIT, pages 307–324 ↑ Christof Koch, The Quest for Consciousness , 2004, page 2 footnote 2 ↑ Tulving, E. 1985. Memory and consciousness. Canadian Psychology 26:1–12 ↑ Franklin, Stan, et al. The role of consciousness in memory. Brains, Minds and Media 1.1 (2005): 38. ↑ Franklin, Stan. Perceptual memory and learning: Recognizing, categorizing, and relating. Proc. Developmental Robotics AAAI Spring Symp. 2005. ↑ Shastri, L. 2002. Episodic memory and cortico-hippocampal interactions. Trends in Cognitive Sciences ↑ Kanerva, Pentti. Sparse distributed memory. MIT press, 1988. ↑ Implicit Learning and Consciousness: An Empirical, Philosophical and Computational Consensus in the Making . Routledge CRC Press . Archived from the original on 2023-06-22 . Retrieved 2023-06-22 . 1 2 Aleksander 1995 . ↑ Dennett, Daniel; Akins, Kathleen (2008-04-10). Multiple drafts model . Scholarpedia . 3 (4): 4321. Bibcode : 2008SchpJ...3.4321D . doi : 10.4249/scholarpedia.4321 . ISSN 1941-6016 . ↑ Functionalism . Stanford Encyclopedia of Philosophy . Archived from the original on 2021-04-18 . Retrieved 2024-09-08 . ↑ Survey Results | Consciousness: identity theory, panpsychism, eliminativism, dualism, or functionalism? . PhilPapers . 2020. ↑ Butlin, Patrick; Long, Robert; Elmoznino, Eric; Bengio, Yoshua; Birch, Jonathan; Constant, Axel; Deane, George; Fleming, Stephen M.; Frith, Chris; Ji, Xu; Kanai, Ryota; Klein, Colin; Lindsay, Grace; Michel, Matthias; Mudrik, Liad; Peters, Megan A. K.; Schwitzgebel, Eric; Simon, Jonathan; VanRullen, Rufin (2023). Consciousness in Artificial Intelligence: Insights from the Science of Consciousness . arXiv : 2308.08708 cs.AI . ↑ Franklin, Stan (January 2003). IDA: A conscious artifact? . Journal of Consciousness Studies . Archived from the original on 2020-07-03 . Retrieved 2024-08-25 . ↑ J. Baars, Bernard; Franklin, Stan (2009). Consciousness is computational: The Lida model of global workspace theory . International Journal of Machine Consciousness . 01 : 23– 32. doi : 10.1142/S1793843009000050 . ↑ ( Sun 2002 ) ↑ Haikonen, Pentti O. (2003). The cognitive approach to conscious machines . Exeter: Imprint Academic. ISBN 978-0-907845-42-3 . ↑ Pentti Haikonen's architecture for conscious machines – Raúl Arrabales Moreno . 2019-09-08. Archived from the original on 2024-09-25 . Retrieved 2023-06-24 . ↑ Freeman, Walter J. (2000). How brains make up their minds . Maps of the mind. New York; Chichester, West Sussex: Columbia University Press. ISBN 978-0-231-12008-1 . ↑ Cotterill, Rodney M. J. (2003). CyberChild - A simulation test-bed for consciousness studies . Journal of Consciousness Studies . 10 ( 4– 5): 31– 45. ISSN 1355-8250 . Archived from the original on 2024-09-25 . Retrieved 2023-06-22 . ↑ Haikonen, Pentti O.; Haikonen, Pentti Olavi Antero (2012). Consciousness and robot sentience . Series on machine consciousness. Singapore: World Scientific. ISBN 978-981-4407-15-1 . ↑ Haikonen, Pentti O. (2019). Consciousness and robot sentience . Series on machine consciousness (2nd ed.). Singapore; Hackensack, NJ; London: World Scientific. ISBN 978-981-12-0504-0 . ↑ Shanahan, Murray (2006). A cognitive architecture that combines internal simulation with a global workspace . Consciousness and Cognition . 15 (2): 433– 449. doi : 10.1016/j.concog.2005.11.005 . ISSN 1053-8100 . PMID 16384715 . S2CID 5437155 . ↑ Haikonen, Pentti O.; Haikonen, Pentti Olavi Antero (2012). chapter 20 . Consciousness and robot sentience . Series on machine consciousness. Singapore: World Scientific. ISBN 978-981-4407-15-1 . ↑ Thaler, S.L., Device for the autonomous generation of useful information ↑ Marupaka, N.; Lyer, L.; Minai, A. (2012). Connectivity and thought: The influence of semantic network structure in a neurodynamical model of thinking (PDF) . Neural Networks . 32 : 147– 158. doi : 10.1016/j.neunet.2012.02.004 . PMID 22397950 . Archived from the original (PDF) on 2016-12-19 . Retrieved 2015-05-22 . ↑ Roque, R. and Barreira, A. (2011). O Paradigma da",
  "cached_at": "2025-10-25T20:05:09.019369"
}