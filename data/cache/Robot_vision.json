{
  "title": "Robotic sensing",
  "summary": "Robotic sensing is a subarea of robotics science intended to provide sensing capabilities to robots. Robotic sensing provides robots with the ability to sense their environments and is typically used as feedback to enable robots to adjust their behavior based on sensed input. Robot sensing includes the ability to see, touch, hear and move and associated algorithms to process and make use of environmental feedback and sensory data. Robot sensing is important in applications such as vehicular automation, robotic prosthetics, and for industrial, medical, entertainment and educational robots",
  "content": "Robotic sensing Subarea of robotics html body.mediawiki This article needs to be updated . Please help update this article to reflect recent events or newly available information. ( August 2022 ) Robotic sensing is a subarea of robotics science intended to provide sensing capabilities to robots . Robotic sensing provides robots with the ability to sense their environments and is typically used as feedback to enable robots to adjust their behavior based on sensed input. Robot sensing includes the ability to see, 1 2 3 touch, 4 5 6 hear 7 and move 8 9 10 and associated algorithms to process and make use of environmental feedback and sensory data. Robot sensing is important in applications such as vehicular automation , robotic prosthetics, and for industrial, medical, entertainment and educational robots. Vision Main articles: Computer vision and Machine vision Method Visual sensing systems can be based on a variety of technologies and methods including the use of camera , sonar , laser and radio frequency identification (RFID) 1 technology. All four methods aim for three procedures—sensation, estimation, and matching. Image processing Image quality is important in applications that require excellent robotic vision. Algorithms based on wavelet transform that are used for fusing images of different spectra and different foci result in improved image quality. 2 Robots can gather more accurate information from the resulting improved image. Usage Visual sensors help robots to identify the surrounding environment and take appropriate action. 3 Robots analyze the image of the immediate environment based on data input from the visual sensor. The result is compared to the ideal, intermediate or end image, so that appropriate movement or action can be determined to reach the intermediate or final goal. Touch 11 Robot skin This section is an excerpt from Electronic skin . edit Electronic skin refers to flexible , stretchable and self-healing electronics that are able to mimic functionalities of human or animal skin. 12 13 The broad class of materials often contain sensing abilities that are intended to reproduce the capabilities of human skin to respond to environmental factors such as changes in heat and pressure. 12 13 14 15 Advances in electronic skin research focuses on designing materials that are stretchy, robust, and flexible. Research in the individual fields of flexible electronics and tactile sensing has progressed greatly; however, electronic skin design attempts to bring together advances in many areas of materials research without sacrificing individual benefits from each field. 16 The successful combination of flexible and stretchable mechanical properties with sensors and the ability to self-heal would open the door to many possible applications including soft robotics , prosthetics, artificial intelligence and health monitoring. 12 16 17 18 Recent advances in the field of electronic skin have focused on incorporating green materials ideals and environmental awareness into the design process. As one of the main challenges facing electronic skin development is the ability of the material to withstand mechanical strain and maintain sensing ability or electronic properties, recyclability and self-healing properties are especially critical in the future design of new electronic skins. 19 Types and examples Examples of the current state of progress in the field of robot skins as of mid-2022 are a robotic finger covered in a type of manufactured living human skin , 20 21 an electronic skin giving biological skin -like haptic sensations and touch/pain-sensitivity to a robotic hand, 22 23 a system of an electronic skin and a human-machine interface that can enable remote sensed tactile perception , and wearable or robotic sensing of many hazardous substances and pathogens , 24 25 and a multilayer tactile sensor hydrogel -based robot skin. 26 27 Tactile discrimination Further information: Tactile sensor This section is an excerpt from Tactile discrimination § Robotic tactile discrimination . edit Early robotic prosthetic hand, made in 1963. On open public display at the main shopping mall in Belgrade. As robots and prosthetic limbs become more complex the need for sensors capable of detecting touch with high tactile acuity becomes more and more necessary. There are many types of tactile sensors used for different tasks. 28 There are three types of tactile sensors. The first, single point sensors, can be compared to a single cell, or whiskers, and can detect very local stimuli. The second type of sensor is a high spatial resolution sensor which can be compared to a human fingertip and is essential for the tactile acuity in robotic hands. The third and final tactile sensor type is a low spatial resolution sensor which has similar tactile acuity as the skin on one's back or arm. 28 These sensors can be placed meaningfully throughout the surface of a prosthetic or a robot to give it the ability to sense touch in similar, if not better, ways than the human counterpart. 28 Signal processing Touch sensory signals can be generated by the robot's own movements. It is important to identify only the external tactile signals for accurate operations. Previous solutions employed the Wiener filter , which relies on the prior knowledge of signal statistics that are assumed to be stationary. Recent solution applies an adaptive filter to the robot's logic. 4 It enables the robot to predict the resulting sensor signals of its internal motions, screening these false signals out. The new method improves contact detection and reduces false interpretation. Usage 29 Touch patterns enable robots to interpret human emotions in interactive applications. Four measurable features— force , contact time, repetition, and contact area change—can effectively categorize touch patterns through the temporal decision tree classifier to account for the time delay and associate them to human emotions with up to 83% accuracy. 5 The Consistency Index 5 is applied at the end to evaluate the level of confidence of the system to prevent inconsistent reactions. Robots use touch signals to map the profile of a surface in hostile environment such as a water pipe. Traditionally, a predetermined path was programmed into the robot. Currently, with the integration of touch sensors , the robots first acquire a random data point; the algorithm 6 of the robot will then determine the ideal position of the next measurement according to a set of predefined geometric primitives. This improves the efficiency by 42%. 5 In recent years, using touch as a stimulus for interaction has been the subject of much study. In 2010, the robot seal PARO was built, which reacts to many stimuli from human interaction, including touch. The therapeutic benefits of such human-robot interaction is still being studied, but has shown very positive results. 30 Hearing Signal processing Accurate audio sensors require low internal noise contribution. Traditionally, audio sensors combine acoustical arrays and microphones to reduce internal noise level. Recent solutions combine also piezoelectric devices. 7 These passive devices use the piezoelectric effect to transform force to voltage , so that the vibration that is causing the internal noise could be eliminated. On average, internal noise up to about 7 dB can be reduced. 7 Robots may interpret strayed noise as speech instructions. Current voice activity detection (VAD) system uses the complex spectrum circle centroid (CSCC) method and a maximum signal-to-noise ratio (SNR) beamformer . 31 Because humans usually look at their partners when conducting conversations, the VAD system with two microphones enable the robot to locate the instructional speech by comparing the signal strengths of the two microphones. Current system is able to cope with Valle, Maurizio (2013). Robotic Tactile Sensing: Technologies and System . Springer. doi : 10.1007/978-94-007-0579-1 . ISBN 978-94-007-0578-4 . 1 2 3 Benight, Stephanie J.; Wang, Chao; Tok, Jeffrey B.H.; Bao, Zhenan (2013). Stretchable and self-healing polymers and devices for electronic skin . Progress in Polymer Science . 38 (12): 1961– 1977. doi : 10.1016/j.progpolymsci.2013.08.001 . 1 2 dos Santos, Andreia; Fortunato, Elvira; Martins, Rodrigo; Águas, Hugo; Igreja, Rui (January 2020). Transduction Mechanisms, Micro-Structuring Techniques, and Applications of Electronic Skin Pressure Sensors: A Review of Recent Advances . Sensors . 20 (16): 4407. Bibcode : 2020Senso..20.4407D . doi : 10.3390/s20164407 . PMC 7472322 . PMID 32784603 . ↑ Chou, Ho-Hsiu; Nguyen, Amanda; Chortos, Alex; To, John W. F.; Lu, Chien; Mei, Jianguo; Kurosawa, Tadanori; Bae, Won-Gyu; Tok, Jeffrey B.-H. (2015-08-24). A chameleon-inspired stretchable electronic skin with interactive colour changing controlled by tactile sensing . Nature Communications . 6 : 8011. Bibcode : 2015NatCo...6.8011C . doi : 10.1038/ncomms9011 . PMC 4560774 . PMID 26300307 . ↑ Hou, Chengyi; Huang, Tao; Wang, Hongzhi; Yu, Hao; Zhang, Qinghong; Li, Yaogang (2013-11-05). A strong and stretchable self-healing film with self-activated pressure sensitivity for potential artificial skin applications . Scientific Reports . 3 (1): 3138. Bibcode : 2013NatSR...3.3138H . doi : 10.1038/srep03138 . ISSN 2045-2322 . PMC 3817431 . PMID 24190511 . 1 2 Hammock, Mallory L.; Chortos, Alex; Tee, Benjamin C.-K.; Tok, Jeffrey B.-H.; Bao, Zhenan (2013-11-01). 25th Anniversary Article: The Evolution of Electronic Skin (E-Skin): A Brief History, Design Considerations, and Recent Progress . Advanced Materials . 25 (42): 5997– 6038. Bibcode : 2013AdM....25.5997H . doi : 10.1002/adma.201302240 . ISSN 1521-4095 . PMID 24151185 . S2CID 205250986 . ↑ Bauer, Siegfried; Bauer-Gogonea, Simona; Graz, Ingrid; Kaltenbrunner, Martin; Keplinger, Christoph; Schwödiauer, Reinhard (2014-01-01). 25th Anniversary Article: A Soft Future: From Robots and Sensor Skin to Energy Harvesters . Advanced Materials . 26 (1): 149– 162. Bibcode : 2014AdM....26..149B . doi : 10.1002/adma.201303349 . ISSN 1521-4095 . PMC 4240516 . PMID 24307641 . ↑ Tee, Benjamin C-K.; Wang, Chao; Allen, Ranulfo; Bao, Zhenan (December 2012). An electrically and mechanically self-healing composite with pressure- and flexion-sensitive properties for electronic skin applications . Nature Nanotechnology . 7 (12): 825– 832. Bibcode : 2012NatNa...7..825T . doi : 10.1038/nnano.2012.192 . ISSN 1748-3395 . PMID 23142944 . ↑ Zou, Zhanan; Zhu, Chengpu; Li, Yan; Lei, Xingfeng; Zhang, Wei; Xiao, Jianliang (2018-02-01). Rehealable, fully recyclable, and malleable electronic skin enabled by dynamic covalent thermoset nanocomposite . Science Advances . 4 (2) eaaq0508. Bibcode : 2018SciA....4..508Z . doi : 10.1126/sciadv.aaq0508 . ISSN 2375-2548 . PMC 5817920 . PMID 29487912 . ↑ Temming, Maria (9 June 2022). Scientists grew living human skin around a robotic finger . Science News . Retrieved 20 July 2022 . ↑ Kawai, Michio; Nie, Minghao; Oda, Haruka; Morimoto, Yuya; Takeuchi, Shoji (6 July 2022). Living skin on a robot . Matter . 5 (7): 2190– 2208. doi : 10.1016/j.matt.2022.05.019 . ISSN 2590-2393 . ↑ Barker, Ross (June 1, 2022). Artificial skin capable of feeling pain could lead to new generation of touch-sensitive robots . University of Glasgow . Retrieved 20 July 2022 . ↑ Liu, Fengyuan; Deswal, Sweety; Christou, Adamos; Shojaei Baghini, Mahdieh; Chirila, Radu; Shakthivel, Dhayalan; Chakraborty, Moupali; Dahiya, Ravinder (June 2022). Printed synaptic transistor–based electronic skin for robots to feel and learn (PDF) . Science Robotics . 7 (67) eabl7286. doi : 10.1126/scirobotics.abl7286 . ISSN 2470-9476 . PMID 35648845 . S2CID 249275626 . ↑ Velasco, Emily (June 2, 2022). Artificial skin gives robots sense of touch and beyond . California Institute of Technology . Retrieved 20 July 2022 . 1 2 Yu, You; Li, Jiahong; Solomon, Samuel A.; Min, Jihong; Tu, Jiaobing; Guo, Wei; Xu, Changhao; Song, Yu; Gao, Wei (June 1, 2022). All-printed soft human-machine interface for robotic physicochemical sensing . Science Robotics . 7 (67) eabn0495. doi : 10.1126/scirobotics.abn0495 . ISSN 2470-9476 . PMC 9302713 . PMID 35648844 . ↑ Yirka, Bob (June 9, 2022). Biomimetic elastomeric robot skin has tactile sensing abilities . Tech Xplore . Retrieved 23 July 2022 . ↑ Park, K.; Yuk, H.; Yang, M.; Cho, J.; Lee, H.; Kim, J. (8 June 2022). A biomimetic elastomeric robot skin using electrical impedance and acoustic tomography for tactile sensing . Science Robotics . 7 (67) eabm7187. doi : 10.1126/scirobotics.abm7187 . ISSN 2470-9476 . PMID 35675452 . S2CID 249520303 . 1 2 3 S. Luo; J. Bimbo; R. Dahiya; H. Liu (December 2017). Robotic tactile perception of object properties: A review . Mechatronics . 48 : 54– 67. arXiv : 1711.03810 . Bibcode : 2017arXiv171103810L . doi : 10.1016/j.mechatronics.2017.11.002 . S2CID 24222234 . ↑ Tactile Sensing—From Humans to Humanoids (PDF) . Archived from the original (PDF) on 2011-08-17. ↑ Archived at Ghostarchive and the Wayback Machine : Cute Baby Seal Robot - PARO Theraputic Robot #DigInfo . YouTube . ↑ Kim HD, et al (2009). Target Speech Detection and Separation for Communication with Humanoid Robots in Noisy Home Environments . Advanced Robotics 23 (15): 2093-2111. ↑ Batliner A, et al (Jan 2011). Searching for the most important feature types signalling emotion-related user states in speech . Computer Speech and Language 25 (1): 4-28. ↑ Special issue on machine olfaction . IEEE Sensors Journal . 11 (12): 3486. 2011. Bibcode : 2011ISenJ..11.3486. . doi : 10.1109/JSEN.2011.2167171 . ↑ Geffen, Wouter H. van; Bruins, Marcel; Kerstjens, Huib A. M. (2016-01-01). Diagnosing viral and bacterial respiratory infections in acute COPD exacerbations by an electronic nose: a pilot study . Journal of Breath Research . 10 (3) 036001. Bibcode : 2016JBR....10c6001V . doi : 10.1088/1752-7155/10/3/036001 . ISSN 1752-7163 . PMID 27310311 . ↑ Stassen, I.; Bueken, B.; Reinsch, H.; Oudenhoven, J. F. M.; Wouters, D.; Hajek, J.; Van Speybroeck, V.; Stock, N.; Vereecken, P. M.; Van Schaijk, R.; De Vos, D.; Ameloot, R. (2016). Towards metal–organic framework based field effect chemical sensors: UiO-66-NH 2 for nerve agent detection . Chem. Sci . 7 (9): 5827– 32. doi : 10.1039/C6SC00987E . hdl : 1854/LU-8157872 . PMC 6024240 . PMID 30034722 . ↑ Gutierrez-Osuna, R. (2002). Pattern analysis for machine olfaction: A review . IEEE Sensors Journal . 2 (3): 189– 202. Bibcode : 2002ISenJ...2..189G . doi : 10.1109/jsen.2002.800688 . ↑ Phaisangittisagul, Ekachai; Nagle, H. Troy (2011). Predicting odor mixture's responses on machine olfaction sensors . Sensors and Actuators B: Chemical . 155 (2): 473– 482. Bibcode : 2011SeAcB.155..473P . doi : 10.1016/j.snb.2010.12.049 . ↑ Vembu, Shankar; Vergara, Alexander; Muezzinoglu, Mehmet K.; Huerta, Ramón (2012). On time series features and kernels for machine olfaction . Sensors and Actuators B: Chemical . 174 : 535– 546. Bibcode : 2012SeAcB.174..535V . doi : 10.1016/j.snb.2012.06.070 . ↑ Vlasov, Yu; Legin, A.; Rudnitskaya, A.; Natale, C. Di; D'Amico, A. (2005-01-01). Nonspecific sensor arrays ( electronic tongue ) for chemical analysis of liquids (IUPAC Technical Report) . Pure and Applied Chemistry . 77 (11): 1965– 1983. doi : 10.1351/pac200577111965 . ISSN 0033-4545 . S2CID 109659409 . ↑ Khalilian, Alireza; Khan, Md. Rajibur Rahaman; Kang, Shin-Won (2017). Highly sensitive and wide-dynamic-range side-polished fiber-optic taste sensor . Sensors and Actuators B: Chemical . 249 : 700– 707. Bibcode : 2017SeAcB.249..700K . doi : 10.1016/j.snb.2017.04.088 . ↑ Sochacki, Grzegorz; Abdulali, Arsen; Iida, Fumiya (2022). Mastication-Enhanced Taste-Based Classification of Multi-Ingredient Dishes for Robotic Cooking . Frontiers in Robotics and AI . 9 886074. doi : 10.3389/frobt.2022.886074 . ISSN 2296-9144 . PMC 9114309 . PMID 35603082 . News release: Taste of the future: Robot chef learns to 'taste' as it goes . University of Cambridge . ↑ Super seers: why some people can see ultraviolet light . New Scientist . 4 December 2019 . Retrieved 4 August 2022 . ↑ Cañón Bermúdez, Gilbert Santiago; Fuchs, Hagen; Bischoff, Lothar; Fassbender, Jürgen; Makarov, Denys (November 2018). Electronic-skin compasses for geomagnetic field-driven artificial magnetoreception and interactive electronics . Nature Electronics . 1 (11): 589– 595. doi : 10.1038/s41928-018-0161-6 . ISSN 2520-1131 . S2CID 125371382 . ↑ Varadharajan, Vivek Shankar; St-Onge, David; Adams, Bram; Beltrame, Giovanni (1 March 2020). SOUL: data sharing for robot swarms (PDF) . Autonomous Robots . 44 (3): 377– 394. doi : 10.1007/s10514-019-09855-2 . ISSN 1573-7527 . S2CID 182651100 . ↑ Scholl, Philipp M.; Brachmann, Martina; Santini, Silvia; Van Laerhoven, Kristof (2014). Integrating Wireless Sensor Nodes in the Robot Operating System . Cooperative Robots and Sensor Networks 2014 . Studies in Computational Intelligence. Vol. 554. Springer. pp. 141– 157. doi : 10.1007/978-3-642-55029-4_7 . ISBN 978-3-642-55028-7 . ↑ Vincent, James (14 November 2019). Security robots are mobile surveillance devices, not human replacements . The Verge . Retrieved 4 August 2022 . ↑ Melinte, Daniel Octavian; Vladareanu, Luige (23 April 2020). Facial Expressions Recognition for Human–Robot Interaction Using Deep Convolutional Neural Networks with Rectified Adam Optimizer . Sensors . 20 (8): 2393. Bibcode : 2020Senso..20.2393M . doi : 10.3390/s20082393 . PMC 7219340 . PMID 32340140 . External links Media related to Robotic sensing at Wikimedia Commons",
  "cached_at": "2025-10-25T20:01:34.680719"
}