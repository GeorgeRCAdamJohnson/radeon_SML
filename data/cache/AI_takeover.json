{
  "title": "AI takeover",
  "summary": "An AI takeover is a hypothetical future event in which autonomous artificial intelligence systems acquire the capability to override human decision-making—through economic manipulation, infrastructure control, or direct intervention—and assume de facto governance. Possible scenarios include replacement of the entire human workforce due to automation, takeover by an artificial superintelligence (ASI), and the notion of a robot uprising",
  "content": "AI takeover Hypothetical outcome of artificial intelligence body.skin-minerva body.skin--responsive Part of a series on Artificial intelligence (AI) Major goals Artificial general intelligence Intelligent agent Recursive self-improvement Planning Computer vision General game playing Knowledge representation Natural language processing Robotics AI safety Approaches Machine learning Symbolic Deep learning Bayesian networks Evolutionary algorithms Hybrid intelligent systems Systems integration Open-source Applications Bioinformatics Deepfake Earth sciences Finance Generative AI Art Audio Music Government Healthcare Mental health Industry Software development Translation Military Physics Projects Philosophy AI alignment Artificial consciousness The bitter lesson Chinese room Friendly AI Ethics Existential risk Turing test Uncanny valley History Timeline Progress AI winter AI boom AI bubble Controversies Deepfake pornography Taylor Swift deepfake pornography controversy Google Gemini image generation controversy Pause Giant AI Experiments Removal of Sam Altman from OpenAI Statement on AI Risk Tay (chatbot) Théâtre D'opéra Spatial Voiceverse NFT plagiarism scandal Glossary Glossary html.skin-theme-clientpref-night v t e An AI takeover is a hypothetical future event in which autonomous artificial intelligence systems acquire the capability to override human decision-making—through economic manipulation, infrastructure control, or direct intervention—and assume de facto governance. Possible scenarios include replacement of the entire human workforce due to automation , takeover by an artificial superintelligence (ASI), and the notion of a robot uprising . Stories of AI takeovers have been popular throughout science fiction , some commentators argue that recent advances have heightened concern about such scenarios. Some public figures such as Stephen Hawking have advocated research into precautionary measures to ensure future superintelligent machines remain under human control. 1 Types Automation of the economy Main article: Technological unemployment The traditional consensus among economists has been that technological progress does not cause long-term unemployment. However, recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete, leaving some people in various sectors without jobs to earn a living, leading to an economic crisis. 2 3 4 5 Many small and medium-size businesses may also be driven out of business if they cannot afford or license the latest robotic and AI technology, and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology. 6 Technologies that may displace workers AI technologies have been widely adopted in recent years. While these technologies have replaced some traditional workers, they also create new opportunities. Industries that are most susceptible to AI-driven automation include transportation, retail, and the military. AI military technologies, for example, can reduce risk by enabling remote operation. A study in 2024 highlights AI's ability to perform routine and repetitive tasks poses significant risks of job displacement, especially in sectors like manufacturing and administrative support. 7 Author Dave Bond argues that as AI technologies continue to develop and expand, the relationship between humans and robots will change; they will become closely integrated in several aspects of life. AI will likely displace some workers while creating opportunities for new jobs in other sectors, especially in fields where tasks are repeatable. 8 9 Researchers from Stanford's Digital Economy Lab report that, since the widespread adoption of generative AI in late 2022, early-career workers (ages 22–25) in the most AI-exposed occupations have experienced a 13 percent relative decline in employment—even after controlling for firm-level shocks—while overall employment has continued to grow robustly. 10 The study further finds that job losses are concentrated in roles where AI automates routine tasks, whereas occupations that leverage AI to augment human work have seen stable or increasing employment. 11 Computer-integrated manufacturing See also: Artificial intelligence in industry Computer-integrated manufacturing uses computers to control the production process. This allows individual processes to exchange information with each other and initiate actions. Although manufacturing can be faster and less error-prone by the integration of computers, the main advantage is the ability to create automated manufacturing processes. Computer-integrated manufacturing is used in automotive, aviation, space, and ship building industries. White-collar machines See also: White-collar worker The 21st century has seen a variety of skilled tasks partially taken over by machines, including translation, legal research, and journalism. Care work, entertainment, and other tasks requiring empathy, previously thought safe from automation, are increasingly performed by robots and AI systems. 12 13 14 15 Autonomous cars An autonomous car is a vehicle that is capable of sensing its environment and navigating without human input. Many such vehicles are operational and others are being developed, with legislation rapidly expanding to allow their use. Obstacles to widespread adoption of autonomous vehicles have included concerns about the resulting loss of driving-related jobs in the road transport industry, and safety concerns. On March 18, 2018, a pedestrian was struck and killed in Tempe, Arizona by an Uber self-driving car. 16 AI-generated content See also: Artificial intelligence art In the 2020s, automated content became more relevant due to technological advancements in AI models, such as ChatGPT , DALL-E , and Stable Diffusion . In most cases, AI-generated content such as imagery, literature, and music are produced through text prompts. These AI models are sometimes integrated into creative programs. AI-generated art may sample and conglomerate existing creative works, producing results that appear similar to human-made content. Low-quality AI-generated visual artwork is referred to as AI slop . Some artists use a tool called Nightshade that alters images to make them detrimental to the training of text-to-image models if scraped without permission, while still looking normal to humans. 17 AI-generated images are a potential tool for scammers and those looking to gain followers on social media, either to impersonate a famous individual or group or to monetize their audience. 18 The New York Times has sued OpenAI , alleging copyright infringement related to the training and outputs of its AI models. 19 20 21 22 23 In 2024, Cambridge and Oxford researchers reported that 57% of the internet's text is either AI-generated or machine-translated using artificial intelligence. 24 25 Eradication Main article: Existential risk from artificial general intelligence Scientists such as Stephen Hawking are confident that superhuman artificial intelligence is physically possible, stating there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains . 26 27 According to Nick Bostrom , a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals; taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine's plans. As a simplified example, a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world's resources to create as many paperclips as possible, and, additionally, prevent humans from shutting it down or using those resources on things other than paperclips. 28 A 2023 Reuters/Ipsos survey showed that 61% of American adults feared AI could pose a threat to civilization. Philosopher Niels Wilde refutes the common thread that artificial intelligence inherently presents a looming threat to humanity, stating that these fears stem from perceived intelligence and lack of transparency in AI systems that more closely reflects the human aspects of it rather than those of a machine. 29 AI alignment research studies how to design AI systems so that they follow intended objectives. 30 Warnings Physicist Stephen Hawking, Microsoft founder Bill Gates , and SpaceX founder Elon Musk have expressed concerns about the possibility that AI could develop to the point that humans could not control it, with Hawking theorizing that this could spell the end of the human race . 31 Stephen Hawking said in 2014 that Success in creating AI would be the biggest event in human history. Unfortunately, it might also be the last, unless we learn how to avoid the risks. Hawking believed that in the coming decades, AI could offer incalculable benefits and risks such as technology outsmarting financial markets , out-inventing human researchers, out-manipulating human leaders, and developing weapons we cannot even understand. In January 2015, Nick Bostrom joined Stephen Hawking, Max Tegmark , Elon Musk, Lord Martin Rees , Jaan Tallinn , and numerous AI researchers in signing the Future of Life Institute 's open letter speaking to the potential risks and benefits associated with artificial intelligence . The signatories believe that research on how to make AI systems robust and beneficial is both important and timely, and that there are concrete research directions that can be pursued today. 32 33 Some focus has been placed on the development of trustworthy AI . Three statements have been posed as to why AI is not inherently trustworthy: 34 1. An entity X is trustworthy only if X has the right motivations, goodwill and/or adheres to moral obligations towards the trustor; 2. AI systems lack motivations, goodwill, and moral obligations; 3. Therefore, AI systems cannot be trustworthy. — Giacomo Zanotti et al. There are additional considerations within this framework of trustworthy AI that go further into the fields of explainable artificial intelligence and respect for human privacy. 35 Zanotti and colleagues argue that while a trustworthy AI may not exist at present that meets all of the requirements of trustworthiness , one may be developed in the future once clear ethical and technical frameworks exist. 34 In fiction Main article: AI takeovers in popular culture See also: Artificial intelligence in fiction and Self-replicating machines in fiction Robots revolt in R.U.R. , a 1928 Czech play translated as Rossum's Universal Robots AI takeover is a recurring theme in science fiction . Fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an AI or robots with anthropomorphic motives who see them as a threat or otherwise have an active desire to fight humans, as opposed to the researchers' concern of an AI that rapidly exterminates humans as a byproduct of pursuing its goals. 36 The idea is seen in Karel Čapek 's R.U.R. , which introduced the word robot in 1920, 37 and can be glimpsed in Mary Shelley 's Frankenstein (published in 1818), as Victor ponders whether, if he grants his monster's request and makes him a wife, they would reproduce and their kind would destroy humanity. 38 According to Toby Ord , the idea that an AI takeover requires robots is a misconception driven by the media and Hollywood. He argues that the most damaging humans in history were not physically the strongest, but that they used words instead to convince people and gain control of large parts of the world. He writes that a sufficiently intelligent AI with access to the internet could scatter backup copies of itself, gather financial and human resources (via cyberattacks or blackmails), persuade people on a large scale, and exploit societal vulnerabilities that are too subtle for humans to anticipate. 39 The word robot from R.U.R. comes from the Czech word robota , meaning laborer or serf . The 1920 play was a protest against the rapid growth of technology, featuring manufactured robots with increasing capabilities who eventually revolt. 40 HAL 9000 (1968) and the original Terminator (1984) are two iconic examples of hostile AI in pop culture. 41 Contributing factors Advantages of superhuman intelligence over humans Nick Bostrom and others have expressed concern that an AI with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence. If its self-reprogramming leads to getting even better at being able to reprogram itself, the result could be a recursive intelligence explosion in which it would rapidly leave human intelligence far behind. Bostrom defines a superintelligence as any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest , and enumerates some advantages a superintelligence would have if it chose to compete against humans: 36 42 Technology research: A machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology Strategizing : A superintelligence might be able to simply outwit human opposition Social manipulation: A superintelligence might be able to recruit human support, 36 or covertly incite a war between humans 43 Economic productivity: As long as a copy of the AI could produce more economic wealth than the cost of its hardware, individual humans would have an incentive to voluntarily allow the Artificial General Intelligence (AGI) to run a copy of itself on their systems Hacking: A superintelligence could find new exploits in computers connected to the Internet, and spread copies of itself onto those systems, or might steal money to finance its plans Sources of AI advantage According to Bostrom, a computer program that faithfully emulates a human brain, or that runs algorithms that are as powerful as the human brain's algorithms, could still become a speed superintelligence if it can think orders of magnitude faster than a human, due to being made of silicon rather than flesh, or due to optimization increasing the speed of the AGI. Biological neurons operate at about 200 Hz, whereas a modern microprocessor operates at a speed of about 2 GHz. Human axons carry action potentials at around 120 m/s, whereas computer signals travel near the speed of light. 36 A network of human-level intelligences designed to network together and share complex thoughts and memories seamlessly, able to collectively work as a giant unified team without friction, or consisting of trillions of human-level intelligences, would become a collective superintelligence . 36 More broadly, any number of qualitative improvements to a human-level AGI could result in a quality superintelligence , perhaps resulting in an AGI as far above us in intelligence as humans are above apes. The number of neurons in a human brain is limited by cranial volume and metabolic constraints, while the number of processors in a supercomputer can be indefinitely expanded. An AGI need not be limited by human constraints on working memory , and might therefore be able to intuitively grasp more complex relationships than humans can. An AGI with specialized cognitive support for engineering or computer programming would have an advantage in these fields, compared with humans who did not evolve specialized cognitive modules for them. Unlike humans, an AGI can spawn copies of itself and tinker with its copies' source code to attempt to further improve its algorithms. 36 Possibility of unfriendly AI preceding friendly AI Morality Main article: AI alignment The sheer complexity of human value systems makes it very difficult to make AI's motivations human-friendly. 36 44 Unless moral philosophy provides us with a flawless ethical theory, an AI's utility function could allow for many potentially harmful scenarios that conform with a given ethical framework but not common sense . According to AI researcher Eliezer Yudkowsky , there is little reason to suppose that an artificially designed mind would have such an adaptation. 45 Odds of conflict Many scholars, including evolutionary psychologist Steven Pinker , argue that a superintelligent machine is likely to coexist peacefully with humans. 46 The fear of cybernetic revolt is often based on interpretations of humanity's history, which is rife with incidents of enslavement and genocide. Such fears stem from a belief that competitiveness and aggression are necessary in any intelligent being's goal system. However, such human competitiveness stems from the evolutionary Pinker argues that a culture of engineering safety will prevent AI researchers from accidentally unleashing malign superintelligence. 46 In contrast, Yudkowsky argues that humanity is less likely to be threatened by deliberately aggressive AIs than by AIs which were programmed such that their goals are unintentionally incompatible with human survival or well-being (as in the film I, Robot and in the short story The Evitable Conflict ). Omohundro suggests that present-day automation systems are not designed for safety and that AIs may blindly optimize narrow utility functions (say, playing chess at all costs), leading them to seek self-preservation and elimination of obstacles, including humans who might turn them off. 49 Precautions The AI control problem is the challenge of ensuring that advanced AI systems reliably act according to human values and intentions, even as they become more capable than humans. 50 Some scholars argue that solutions to the control problem might also find applications in existing non-superintelligent AI. 51 Major approaches to the control problem include alignment , which aims to align AI goal systems with human values, and capability control , which aims to reduce an AI system's capacity to harm humans or gain control. An example of capability control is to research whether a superintelligent AI could be successfully confined in an AI box . According to Bostrom, such capability control proposals are not reliable or sufficient to solve the control problem in the long term, but may potentially act as valuable supplements to alignment efforts. 36 Prevention through AI alignment This paragraph is an excerpt from AI alignment . edit In the field of artificial intelligence (AI), alignment aims to steer AI systems toward a person's or group's intended goals, preferences, or ethical principles. An AI system is considered aligned if it advances the intended objectives. A misaligned AI system pursues unintended objectives. 52 See also Philosophy of artificial intelligence Artificial intelligence arms race Autonomous robot Industrial robot Mobile robot Self-replicating machine Cyberocracy Effective altruism Existential risk from artificial general intelligence Future of Humanity Institute Global catastrophic risk (existential risk) Government by algorithm Human extinction Machine ethics Machine learning / Deep learning Transhumanism Self-replication Superintelligence Superintelligence: Paths, Dangers, Strategies Technophobia Technological singularity References ↑ body:not(.skin-timeless):not(.skin-minerva) Lewis, Tanya (2015-01-12). Don't Let Artificial Intelligence Take Over, Top Scientists Warn . LiveScience . Purch . Archived from the original on 2018-03-08 . Retrieved October 20, 2015 . Stephen Hawking and dozens of other top scientists and technology leaders have signed a letter warning of the potential dangers of developing artificial intelligence (AI). ↑ Lee, Kai-Fu (2017-06-24). The Real Threat of Artificial Intelligence . The New York Times . Archived from the original on 2020-04-17 . Retrieved 2017-08-15 . These tools can outperform human beings at a given task. This kind of A.I. is spreading to thousands of domains, and as it does, it will eliminate many jobs. ↑ Larson, Nina (2017-06-08). AI 'good for the world'... says ultra-lifelike robot . Phys.org . Archived from the original on 2020-03-06 . Retrieved 2017-08-15 . Among the feared consequences of the rise of the robots is the growing impact they will have on human jobs and economies. ↑ Santini, Jean-Louis (2016-02-14). Intelligent robots threaten millions of jobs . Phys.org . Archived from the original on 2019-01-01 . Retrieved 2017-08-15 . We are approaching a time when machines will be able to outperform humans at almost any task, said Moshe Vardi, director of the Institute for Information Technology at Rice University in Texas. ↑ Williams-Grut, Oscar (2016-02-15). Robots will steal your job: How AI could increase unemployment and inequality . Businessinsider.com . Business Insider . Archived from the original on 2017-08-16 . Retrieved 2017-08-15 . Top computer scientists in the US warned that the rise of artificial intelligence (AI) and robots in the workplace could cause mass unemployment and dislocated economies, rather than simply unlocking productivity gains and freeing us all up to watch TV and play sports. ↑ How can SMEs prepare for the rise of the robots? . LeanStaff . 2017-10-17. Archived from the original on 2017-10-18 . Retrieved 2017-10-17 . ↑ Hassan Soueidan, Mohamad; Shoghari, Rodwan (2024-05-09). The Impact of Artificial Intelligence on Job Loss: Risks for Governments . Technium Social Sciences Journal . 57 : 206– 223. doi : 10.47577/tssj.v57i1.10917 . ↑ Frank, Morgan (2019-03-25). Toward understanding the impact of artificial intelligence on labor . Proceedings of the National Academy of Sciences of the United States of America . 116 (14): 6531– 6539. Bibcode : 2019PNAS..116.6531F . doi : 10.1073/pnas.1900949116 . PMC 6452673 . PMID 30910965 . ↑ Bond, Dave (2017). Artificial Intelligence . pp. 67– 69. ↑ Brynjolfsson, Erik (2025-08-26). Canaries in the Coal Mine? Six Facts about the Recent Employment Effects of Artificial Intelligence (PDF) . Stanford Digital Economy Lab . Retrieved 2025-08-26 . ↑ AI is already taking jobs away from entry-level workers . Axios . 2025-08-26 . Retrieved 2025-08-26 . ↑ Skidelsky, Robert (2013-02-19). Rise of the robots: what will the future of work look like? . The Guardian . London, England. Archived from the original on 2019-04-03 . Retrieved 14 July 2015 . ↑ Bria, Francesca (February 2016). The robot economy may already have arrived . openDemocracy . Archived from the original on 17 May 2016 . Retrieved 20 May 2016 . ↑ Srnicek, Nick (March 2016). 4 Reasons Why Technological Unemployment Might Really Be Different This Time . novara wire. Archived from the original on 25 June 2016 . Retrieved 20 May 2016 . ↑ Brynjolfsson, Erik; McAfee, Andrew (2014). passim , see esp Chpt. 9 . The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies . W. W. Norton Company. ISBN 978-0393239355 . ↑ Wakabayashi, Daisuke (March 19, 2018). Self-Driving Uber Car Kills Pedestrian in Arizona, Where Robots Roam . New York Times . New York, New York. Archived from the original on April 21, 2020 . Retrieved March 23, 2018 . ↑ This new data poisoning tool lets artists fight back against generative AI . MIT Technology Review . 2023-10-23 . Retrieved 2025-08-03 . ↑ DiResta, Renée; Goldstein, Josh A. (2024-08-15). How spammers and scammers leverage AI-generated images on Facebook for audience growth . Harvard Kennedy School Misinformation Review . doi : 10.37016/mr-2020-151 . ↑ Jiang, Harry H.; Brown, Lauren; Cheng, Jessica; Khan, Mehtab; Gupta, Abhishek; Workman, Deja; Hanna, Alex; Flowers, Johnathan; Gebru, Timnit (29 August 2023). AI Art and its Impact on Artists . Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society . Association for Computing Machinery. pp. 363– 374. doi : 10.1145/3600211.3604681 . ISBN 979-8-4007-0231-0 . ↑ Ghosh, Avijit; Fossas, Genoveva (19 November 2022). Can There be Art Without an Artist? . arXiv : 2209.07667 cs.AI . ↑ Shan, Shawn; Cryan, Jenna; Wenger, Emily; Zheng, Haitao; Hanocka, Rana; Zhao, Ben Y. (3 August 2023). Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models . arXiv : 2302.04222 cs.CR . ↑ Brooks, Libby (27 February 2024). Glasgow Willy Wonka experience called a 'farce' as tickets refunded . The Guardian . Retrieved 2 April 2024 . ↑ Metz, Cade; Robertson, Katie (27 February 2024). OpenAI Seeks to Dismiss Parts of The New York Times's Lawsuit . The New York Times . Retrieved 4 April 2024 . ↑ Thompson, Brian; Mehak Preet Dhaliwal; Frisch, Peter; Domhan, Tobias; Federico, Marcello (2024). A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism . arXiv : 2401.05749 cs.CL . ↑ Is AI quietly killing itself - and the Internet? . Forbes Australia . 2024-09-02 . Retrieved 2025-08-02 . ↑ Hawking, Stephen; Russell, Stuart J. ; Tegmark, Max ; Wilczek, Frank (1 May 2014). Stephen Hawking: 'Transcendence looks at the implications of artificial intelligence - but are we taking AI seriously enough?' . The Independent . Archived from the original on 2015-10-02 . Retrieved 1 April 2016 . ↑ Müller, Vincent C. ; Bostrom, Nick (2016). Future Progress in Artificial Intelligence: A Survey of Expert Opinion (PDF) . Fundamental Issues of Artificial Intelligence . Springer. pp. 555– 572. doi : 10.1007/978-3-319-26485-1_33 . ISBN 978-3-319-26483-7 . Archived (PDF) from the original on 2022-05-31 . Retrieved 2022-06-16 . AI systems will... reach overall human ability... very likely (with 90% probability) by 2075. From reaching human ability, it will move on to superintelligence within 30 years (75%)... So, (most of the AI experts responding to the surveys) think that superintelligence is likely to come in a few decades... ↑ Bostrom, Nick (2012). The Superintelligent Will: Motivation and Instrumental Rationality in Advanced Artificial Agents (PDF) . Minds and Machines . 22 (2). Springer: 71– 85. doi : 10.1007/s11023-012-9281-3 . S2CID 254835485 . Archived (PDF) from the original on 2022-07-09 . Retrieved 2022-06-16 . ↑ Wilde, Niels (2025-04-14). Fear of artificial intelligence or fear of looking in the mirror? Revisiting the Western machine-takeover imaginary . AI Society . doi : 10.1007/s00146-025-02355-1 . ISSN 0951-5666 . ↑ Bruiger, Dan (2025). Reflections on the AI alignment problem . AI Society . 40 (6): 4383– 4392. doi : 10.1007/s00146-025-02211-2 . ISSN 0951-5666 . ↑ Rawlinson, Kevin (29 January 2015). Microsoft's Bill Gates insists AI is a threat . BBC News . Archived from the original on 29 January 2015 . Retrieved 30 January 2015 . ↑ The Future of Life Institute Open Letter . The Future of Life Institute. 28 October 2015. Archived from the original on 29 March 2019 . Retrieved 29 March 2019 . ↑ Bradshaw, Tim (11 January 2015). Scientists and investors warn on AI . The Financial Times. Archived from the original on 7 February 2015 . Retrieved 4 March 2015 . 1 2 Zanotti, Giacomo; Petrolo, Mattia; Chiffi, Daniele; Schiaffonati, Viola (2024). Keep trusting! A plea for the notion of Trustworthy AI . AI Society . 39 (6): 2691– 2702. doi : 10.1007/s00146-023-01789-9 . ISSN 0951-5666 . ↑ Russell, Stuart J.; Norvig, Peter (2021). Artificial intelligence: A modern approach (4th ed.). Pearson. pp. 5, 1003. ISBN 9780134610993 . Retrieved September 12, 2022 . 1 2 3 4 5 6 7 8 Bostrom, Nick. Superintelligence: Paths, Dangers, Strategies . ↑ The Origin Of The Word 'Robot' . Science Friday (public radio) . 22 April 2011. Archived from the original on 14 March 2020 . Retrieved 30 April 2020 . ↑ Botkin-Kowacki, Eva (28 October 2016). A female Frankenstein would lead to humanity's extinction, say scientists . Christian Science Monitor . Archived from the original on 26 February 2021 . Retrieved 30 April 2020 . ↑ Ord, Toby (2020). Unaligned artificial intelligence . The precipice: existential risk and the future of humanity . London, England and New York, New York: Bloomsbury academic. ISBN 978-1-5266-0023-3 . ↑ Hockstein, N. G.; Gourin, C. G.; Faust, R. A.; Terris, D. J. (17 March 2007). A history of robots: from science fiction to surgical robotics . Journal of Robotic Surgery . 1 (2): 113– 118. doi : 10.1007/s11701-007-0021-2 . PMC 4247417 . PMID 25484946 . ↑ Hellmann, Melissa (21 September 2019). AI 101: What is artificial intelligence and where is it going? . The Seattle Times . Archived from the original on 21 April 2020 . Retrieved 30 April 2020 . ↑ Babcock, James; Krámar, János; Yampolskiy, Roman V. (2019). Guidelines for Artificial Intelligence Containment . Next-Generation Ethics . pp. 90– 112. arXiv : 1707.08476 . doi : 10.1017/9781108616188.008 . ISBN 9781108616188 . S2CID 22007028 . ↑ Baraniuk, Chris (23 May 2016). Checklist of worst-case scenarios could help prepare for evil AI . New Scientist . Archived from the original on 21 September 2016 . Retrieved 21 September 2016 . ↑ Muehlhauser, Luke; Helm, Louie (2012). Intelligence Explosion and Machine Ethics (PDF) . Singularity Hypotheses: A Scientific and Philosophical Assessment . Springer. Archived (PDF) from the original on 2015-05-07 . Retrieved 2020-10-02 . ↑ Yudkowsky, Eliezer (2011). Complex Value Systems in Friendly AI . Artificial General Intelligence . Lecture Notes in Computer Science. Vol. 6830. pp. 388– 393. doi : 10.1007/978-3-642-22887-2_48 . ISBN 978-3-642-22886-5 . ISSN 0302-9743 . 1 2 Pinker, Steven (13 February 2018). We're told to fear robots. But why do we think they'll turn on us? . Popular Science . Archived from the original on 20 July 2020 . Retrieved 8 June 2020 . ↑ Creating a New Intelligent Species: Choices and Responsibilities for Artificial Intelligence Designers Archived February 6, 2007, at the Wayback Machine - Singularity Institute for Artificial Intelligence , 2005 ↑ Omohundro, Stephen M. (June 2008). The basic AI drives (PDF) . Artificial General Intelligence 2008. pp. 483– 492. Archived (PDF) from the original on 2020-10-10 . Retrieved 2020-10-02 . ↑ Tucker, Patrick (17 Apr 2014). Why There Will Be A Robot Uprising . Defense One. Archived from the original on 6 July 2014 . Retrieved 15 July 2014 . ↑ Russell, Stuart J. (8 October 2019). Human Compatible: Artificial Intelligence and the Problem of Control . Penguin. ISBN 978-0-525-55862-0 . OCLC 1237420037 . ↑ Google developing kill switch for AI . BBC News . 8 June 2016. Archived from the original on 11 June 2016 . Retrieved 7 June 2020 . ↑ Russell, Stuart J.; Norvig, Peter (2021). Artificial intelligence: A modern approach (4th ed.). Pearson. pp. 5, 1003. ISBN 978-0-13-461099-3 . Retrieved September 12, 2022 . External links TED talk : Can we build AI without losing control over it? by Sam Harris body.skin--responsive v t e Existential risk from artificial intelligence Concepts AGI AI alignment AI boom AI capability control AI safety AI takeover Consequentialism Effective accelerationism Ethics of artificial intelligence Existential risk from artificial intelligence Friendly artificial intelligence Instrumental convergence Vulnerable world hypothesis Intelligence explosion Jobpocalypse Longtermism Machine ethics Right to reality Suffering risks Superintelligence Technological singularity Organizations Alignment Research Center Center for AI Safety Center for Applied Rationality Center for Human-Compatible Artificial Intelligence Centre for the Study of Existential Risk EleutherAI Future of Humanity Institute Future of Life Institute Google DeepMind Humanity+ Institute for Ethics and Emerging Technologies Leverhulme Centre for the Future of Intelligence Machine Intelligence Research Institute OpenAI Safe Superintelligence People Scott Alexander Sam Altman Yoshua Bengio Nick Bostrom Paul Christiano Eric Drexler Sam Harris Stephen Hawking Dan Hendrycks Geoffrey Hinton Bill Joy Shane Legg Elon Musk Steve Omohundro Huw Price Martin Rees Stuart J. Russell Ilya Sutskever Jaan Tallinn Max Tegmark Alan Turing Frank Wilczek Roman Yampolskiy Eliezer Yudkowsky Other Artificial Intelligence Act Do You Trust This Computer? Human Compatible Open letter on artificial intelligence (2015) Our Final Invention Roko's basilisk Statement on AI risk of extinction Superintelligence: Paths, Dangers, Strategies The Precipice If Anyone Builds It, Everyone Dies Category v t e Global catastrophic risks Future of the Earth Future of an expanding universe Ultimate fate of the universe Human extinction risk estimates Technological Chemical warfare Cyberattack Cyberwarfare Cyberterrorism Cybergeddon Ransomware Gray goo Nanoweapons Kinetic bombardment Kinetic energy weapon Nuclear warfare Mutual assured destruction Dead Hand Doomsday Clock Doomsday device Antimatter weapon Electromagnetic pulse (EMP) Safety of high-energy particle collision experiments Micro black hole Strangelet Synthetic intelligence / Artificial intelligence AI takeover Existential risk from artificial intelligence Technological singularity Transhumanism Sociological Anthropogenic hazard Collapsology Doomsday argument Self-indication assumption doomsday argument rebuttal Self-referencing doomsday argument rebuttal Economic collapse Malthusian catastrophe New World Order (conspiracy theory) Nuclear holocaust cobalt famine winter Riots Social crisis Societal collapse State collapse World War III Ecological Climate change Anoxic event Biodiversity loss Mass mortality event Cascade effect Cataclysmic pole shift hypothesis Deforestation Desertification Plant or animal species extinctions Civilizational collapse Tipping points Climate sensitivity Flood basalt Global dimming Global terrestrial stilling Global warming Hypercane Ice age Ecocide Ecological collapse Environmental degradation Habitat destruction Human impact on the environment coral reefs on marine life Land degradation Land consumption Land surface effects on climate Ocean acidification Ozone depletion Resource depletion Sea level rise Supervolcano winter Verneshot Water pollution Water scarcity Earth Overshoot Day Overexploitation Overpopulation Human overpopulation Biological Extinction Extinction event Holocene extinction Human extinction List of extinction events Genetic erosion Genetic pollution Others Biodiversity loss Decline in amphibian populations Decline in insect populations Biotechnology risk Biological agent Biological warfare Bioterrorism Colony collapse disorder Defaunation Dysgenics Interplanetary contamination Pandemic Pollinator decline Overfishing Astronomical Big Crunch Big Rip Coronal mass ejection Cosmological phase transition Geomagnetic storm False vacuum decay Gamma-ray burst Heat death of the universe Proton decay Virtual black hole Impact event Asteroid impact avoidance Asteroid impact prediction Potentially hazardous object Near-Earth object winter Rogue planet Rogue star Near-Earth supernova Hypernova Micronova Solar flare Stellar collision Eschatological Buddhist Maitreya Three Ages Hindu Kalki Kali Yuga Last Judgement Second Coming 1 Enoch Daniel Abomination of desolation Prophecy of Seventy Weeks Messiah Christian Futurism Historicism Interpretations of Revelation Idealism Preterism 2 Esdras 2 Thessalonians Man of sin Katechon Antichrist Book of Revelation Events Four Horsemen of the Apocalypse Seven bowls Seven seals The Beast Two witnesses War in Heaven Whore of Babylon Great Apostasy New Earth New Jerusalem Olivet Discourse Great Tribulation Son of perdition Sheep and Goats Islamic Al-Qa'im Beast of the Earth Dhu al-Qarnayn Dhul-Suwayqatayn Dajjal Israfil Mahdi Sufyani Jewish Messiah War of Gog and Magog Third Temple Norse Zoroastrian Saoshyant Others 2011 end times pre",
  "cached_at": "2025-10-25T20:06:04.798859"
}