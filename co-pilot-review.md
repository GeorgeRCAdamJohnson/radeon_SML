# Co-pilot Review

Date: 2025-10-25

This document is a candid review based on recent work in the repository (crawler, KB repairs, reasoning agent, server, Docker, and deployment attempts). It summarizes an overall rating, inferred role/experience, strengths, and prioritized areas for improvement with concrete next steps you can act on immediately.

## Summary rating

- Score: 8 / 10

Reason: you demonstrate strong, practical engineering across data pipelines, model integration, backend services, and deployments. You iterate quickly and ship useful diagnostics and repair tools. The main reasons the score is not higher are process/infra gaps (data-as-source, missing CI gates, ad-hoc scripts) that caused avoidable operational friction.

## Inferred role and experience

- Likely role: ML/AI Engineer (applied) or Research Engineer who also handles backend and infra. You appear comfortable across the full stack (data, model, server, deployment).
- Estimated experience: ~4–8 years. You know production tooling and make pragmatic trade-offs.

## Strengths observed

- Initiative and velocity: you implemented crawler enhancements, KB repair scripts, diagnostics, and runners without stalling.
- Troubleshooting depth: you debugged Windows encoding issues, port conflicts, import path problems, and container KB absence.
- Repro artifacts: you produce outputs (reports, saved query results) which helps later QA and debugging.

## Areas for improvement (prioritized)

1. Data & artifact management (High)
   - Problem: generated KB JSON treated like regular source; containers built without it caused silent fallback.
   - Fix: treat KBs as canonical artifacts (GCS / S3 / GitHub Releases) and fetch them during build or startup. Add `data/README.md` and a `scripts/publish_kb.py` to upload canonical artifacts.

2. Fail-fast startup & observability (High)
   - Problem: silent fallback to built-in KB hides issues in stage/prod.
   - Fix: add startup checks (entrypoint) that validate KB presence/shape, write structured diagnostics, and exit non-zero if missing. Extend `/api/health` to include KB counts.

3. CI and testing (High)
   - Problem: regressions found manually.
   - Fix: add GitHub Actions for lint → pytest → build → KB-check container. Add `tests/test_kb_loader.py`, `tests/test_server_health.py` and small e2e stage smoke tests.

4. Packaging & script hygiene (Medium)
   - Problem: scripts used sys.path hacks and were fragile from different CWDs.
   - Fix: convert `scripts/` to a package (`radeon_ai.scripts`) and provide `python -m` entrypoints or console_scripts in pyproject.

5. Retrieval & index design (Medium)
   - Problem: retrieval returned zero relevant sources for some queries (Gundam example).
   - Fix: build a title→article map and a lightweight keyword index (TF-IDF/BM25); optionally add vector search later. Persist index to disk for fast startup.

6. Agent contract & engineering culture (Medium)
   - Problem: ad-hoc helper scripts and inconsistent agent contracts.
   - Fix: write `AGENT_GUIDELINES.md` with input/output schemas, error modes, test requirements, and logging format. Enforce via PR checklist.

7. Dev/Stage/Prod separation & runbooks (Medium)
   - Define: Dev = local builds (hot-reload, mounts), Stage = local docker compose smoke-tests, Prod = GCP Cloud Run with artifact-provided KB.
   - Add runbook and small scripts: `make dev`, `make stage`, `make deploy`.

8. Observability & metrics (Medium)
   - Emit structured JSON logs with retrieval_count, top_k sources, fallback flags, and git commit id. Collect basic metrics for QA.

9. Documentation & onboarding (Low)
   - Keep `LESSONS_LEARNED_v2.md`, add `CONTRIBUTING.md` and `RUNBOOK.md` for common ops.

## Recommended immediate actions (pick one)

- A1 (highest-impact, 1–2 hours): Add `scripts/check_kb_and_start.py` (fail-fast) and update `Dockerfile`/entrypoint to use it. I can implement this now.
- A2 (quick, 15–30 min): Add `docker-compose.override.yml` for dev mounts and `data/README.md` explaining KB regeneration and canonical storage.
- B1 (2–6 hours): Add unit tests for KB loader and a minimal GH Actions `ci.yml` that runs pytest and linters on PRs.
- C1 (1–3 days): Implement a small indexer (title→article + TF-IDF/BM25) and persist the index for fast retrieval.
- D1 (planning): Draft `AGENT_GUIDELINES.md` and a PR checklist to enforce the rules above.

If you tell me which option to start (A1/A2/B1/C1/D1) I will implement it on a short-lived branch and run the local checks.

## Notes on workflow and strengths

- You move fast and make pragmatic choices — that is a huge advantage. The biggest gains will come from a small upfront investment (1–2 hours) to add fail-fast checks and CI gates that prevent future time-consuming debugging.

---

Generated by the co-pilot assistant as a repository-facing review.
